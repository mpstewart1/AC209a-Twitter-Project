{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fde66de8f3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/plotly/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m from plotly import (plotly, dashboard_objs, graph_objs, grid_objs, tools,\n\u001b[0m\u001b[1;32m     32\u001b[0m                     utils, session, offline, colors, io)\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/plotly/plotly/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m from . plotly import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msign_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mupdate_plot_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/plotly/plotly/plotly.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchunked_requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/plotly/graph_objs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sankey\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSankey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msankey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/plotly/graph_objs/scatter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhoverlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_error_y\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mErrorY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_error_x\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mErrorX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_relax_case\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import jsonpickle\n",
    "import os\n",
    "import keras\n",
    "import tensorflow\n",
    "from textblob import TextBlob \n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import csv\n",
    "import gensim\n",
    "import logging\n",
    "import tempfile\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from string import punctuation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pyLDAvis.gensim\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import emoji\n",
    "import time\n",
    "\n",
    "init_notebook_mode(connected=True) #do not miss this line\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer keys and access tokens, used for OAuth\n",
    "consumer_key = '1K7KS692MTDzqWfHvvAPPSlqE'\n",
    "consumer_secret = 'bRy95ycRGxry1EsSaQfnOVuZl31A5Sw6sn5xdXr2qcZkUmm0Aw'\n",
    "access_token = '1053856790834753536-vLIZETTNJ9eFxsCtCNV4UCk0eOpj7g'\n",
    "access_token_secret = 'gbJVvuKGYVJUAzXpWA2NhbaFezK5PBqJNfMhaObbXPDX7'\n",
    "\n",
    "#auth = tweepy.OAuthHandler('pr0AH7Ot5sZmig4u3bA6j51ty', 'tNteF0tRlEjKJfkkWQaIv5myqT9oBqrIVOYPQJOMjBTJhn9SAF')\n",
    "#auth.set_access_token('934846563825930241-yO5rosUB4x8eFMO0J7IXV1UZM0RzbgL', 'CbqfvlRonXo2JiIyxqCqeZynwkslNcDPmGFQ9KBEh8Mch')\n",
    " \n",
    "#OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "user = api.me()\n",
    " \n",
    "print('Name: ' + user.name)\n",
    "print('Location: ' + user.location)\n",
    "print('Friends: ' + str(user.friends_count))\n",
    "\n",
    "auth = tweepy.OAuthHandler('pr0AH7Ot5sZmig4u3bA6j51ty', 'tNteF0tRlEjKJfkkWQaIv5myqT9oBqrIVOYPQJOMjBTJhn9SAF')\n",
    "auth.set_access_token('934846563825930241-yO5rosUB4x8eFMO0J7IXV1UZM0RzbgL', 'CbqfvlRonXo2JiIyxqCqeZynwkslNcDPmGFQ9KBEh8Mch')\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "mashape_key = \"uIX3UUkrh7mshux9VLXhN1FcUYY0p1ZEJpCjsnCHKddXFfIzhf\"\n",
    "twitter_app_auth = {\n",
    "    'consumer_key': 'pr0AH7Ot5sZmig4u3bA6j51ty',\n",
    "    'consumer_secret': 'tNteF0tRlEjKJfkkWQaIv5myqT9oBqrIVOYPQJOMjBTJhn9SAF',\n",
    "    'access_token': '934846563825930241-yO5rosUB4x8eFMO0J7IXV1UZM0RzbgL',\n",
    "    'access_token_secret': 'CbqfvlRonXo2JiIyxqCqeZynwkslNcDPmGFQ9KBEh8Mch',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load legitimate users file\n",
    "legit_df = pd.DataFrame.from_csv('legitimate_users.txt',header=None,sep='\\t')\n",
    "legit_df.reset_index(inplace=True)\n",
    "legit_list = list(legit_df[0])\n",
    "\n",
    "# load bot users \n",
    "bot_df = pd.DataFrame.from_csv('bot_users.txt',header=None,sep='\\t')\n",
    "bot_df.reset_index(inplace=True)\n",
    "bot_list = list(bot_df[0])\n",
    "\n",
    "# temporarily only use first 1000 bots and legit users\n",
    "legit_list = legit_list[0:1000]\n",
    "bot_list = bot_list[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name, bots_list_bool):\n",
    "    \n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "#     auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#     auth.set_access_token(access_token, access_token_secret)\n",
    "#     api = tweepy.API(auth)\n",
    "\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        try:\n",
    "            # if user id is inputted \n",
    "            val = int(screen_name)\n",
    "\n",
    "            #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "            new_tweets = api.user_timeline(user_id = screen_name,count=200)#, tweet_mode = 'extended')\n",
    "\n",
    "        except ValueError:\n",
    "            # input was a string (screen name)\n",
    "            #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "            new_tweets = api.user_timeline(screen_name = screen_name,count=200)#,tweet_mode = 'extended')\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #save the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        #keep grabbing tweets until there are no tweets left to grab\n",
    "        while len(new_tweets) > 0:\n",
    "            print(\"getting tweets before {}\".format(oldest))\n",
    "\n",
    "            #all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "            #save most recent tweets\n",
    "            alltweets.extend(new_tweets)\n",
    "\n",
    "            #update the id of the oldest tweet less one\n",
    "            oldest = alltweets[-1].id - 1\n",
    "\n",
    "            print(\"...{} tweets downloaded so far\".format(len(alltweets)))\n",
    "\n",
    "        screen_name = alltweets[0].user.screen_name\n",
    "        user_id = alltweets[0].user.id_str\n",
    "        \n",
    "    \n",
    "        #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "        outtweets = [[screen_name, user_id, tweet.id_str, tweet.text,tweet.source] for tweet in alltweets\n",
    "                    ]\n",
    "\n",
    "        # potential other features\n",
    "        #tweet.created_at, tweet.retweets, tweet.retweet_count, tweet.retweeted,tweet.lang,  tweet.geo,\n",
    "        #              tweet.favorite, tweet.favorite_count, tweet.favorited,tweet.place,tweet.entities,\n",
    "        \n",
    "        #\"created_at\",\"retweets\",\"retweet_count\",\n",
    "        #                     \"retweeted\",\"favorite\", \"favorite_count\", \"favorited\", \"entities\",\"lang\",\"place\",\"geo\",\n",
    "\n",
    "        #write the csv\n",
    "\n",
    "        # choose file path\n",
    "        if bots_list_bool:\n",
    "            filepath ='data_NLP/bots/{}_tweets.csv'\n",
    "        else:\n",
    "            filepath ='data_NLP/legit/{}_tweets.csv'\n",
    "\n",
    "        with open(filepath.format(user_id), 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"author\",\"id\",\"text\",\"source\"])\n",
    "            writer.writerows(outtweets)\n",
    "\n",
    "        pass\n",
    "    except Exception as e: \n",
    "        print('Exception was:', e)\n",
    "        print(\"Failed to load data for user {}\".format(screen_name))\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Legit User Number 19---\n",
      "getting tweets before 236127121695711231\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2157321\n",
      "--- Fetching Legit User Number 20---\n",
      "getting tweets before 457959017667510271\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2219081\n",
      "--- Fetching Legit User Number 21---\n",
      "getting tweets before 1048221407325253632\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2243161\n",
      "--- Fetching Legit User Number 22---\n",
      "getting tweets before 1044143902645788671\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2269491\n",
      "--- Fetching Legit User Number 23---\n",
      "getting tweets before 895774831987314688\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2695911\n",
      "--- Fetching Legit User Number 24---\n",
      "getting tweets before 1067020154264010757\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 2884771\n",
      "--- Fetching Legit User Number 25---\n",
      "getting tweets before 1065242804492926976\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 3060631\n",
      "--- Fetching Legit User Number 26---\n",
      "getting tweets before 323291719829426177\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 3076591\n",
      "--- Fetching Legit User Number 27---\n",
      "getting tweets before 1061165868506365951\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 3136731\n",
      "--- Fetching Legit User Number 28---\n",
      "getting tweets before 814129310319726591\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 3291901\n",
      "--- Fetching Legit User Number 29---\n",
      "getting tweets before 529998427011026943\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 3881391\n"
     ]
    }
   ],
   "source": [
    "# get first 10 bot users\n",
    "for i in range(19,30):\n",
    "    print(\"--- Fetching Legit User Number {}---\".format(i))\n",
    "    get_all_tweets(bot_list[i], True)\n",
    "    #time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Legit User Number 500---\n",
      "getting tweets before 1061389470698659845\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7705112\n",
      "--- Fetching Legit User Number 501---\n",
      "getting tweets before 1065360401163083775\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7737912\n",
      "--- Fetching Legit User Number 502---\n",
      "getting tweets before 756232235892613119\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7760272\n",
      "--- Fetching Legit User Number 503---\n",
      "getting tweets before 950420201828360191\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7760472\n",
      "--- Fetching Legit User Number 504---\n",
      "getting tweets before 624406885484118015\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7777272\n",
      "--- Fetching Legit User Number 505---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7777392\n",
      "--- Fetching Legit User Number 506---\n",
      "getting tweets before 1008018937613778945\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7780092\n",
      "--- Fetching Legit User Number 507---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 7782002\n",
      "--- Fetching Legit User Number 508---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7801642\n",
      "--- Fetching Legit User Number 509---\n",
      "getting tweets before 26274659214\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7814852\n",
      "--- Fetching Legit User Number 510---\n",
      "getting tweets before 476566717963841538\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7842262\n",
      "--- Fetching Legit User Number 511---\n",
      "getting tweets before 1052060728578912255\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7870952\n",
      "--- Fetching Legit User Number 512---\n",
      "getting tweets before 692385776286437375\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7877092\n",
      "--- Fetching Legit User Number 513---\n",
      "getting tweets before 1067213061428260863\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7901732\n",
      "--- Fetching Legit User Number 514---\n",
      "getting tweets before 580817080628445184\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7919102\n",
      "--- Fetching Legit User Number 515---\n",
      "getting tweets before 87498187513933823\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7936262\n",
      "--- Fetching Legit User Number 516---\n",
      "getting tweets before 954728618076196866\n",
      "...201 tweets downloaded so far\n",
      "getting tweets before 448010115074244607\n",
      "...201 tweets downloaded so far\n",
      "--- Fetching Legit User Number 517---\n",
      "getting tweets before 905769194083545087\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7990062\n",
      "--- Fetching Legit User Number 518---\n",
      "getting tweets before 743056626886844419\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 7994952\n",
      "--- Fetching Legit User Number 519---\n",
      "getting tweets before 1055110223520821247\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8005012\n",
      "--- Fetching Legit User Number 520---\n",
      "getting tweets before 1007409515065536511\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8011432\n",
      "--- Fetching Legit User Number 521---\n",
      "getting tweets before 1063944919377620991\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8048482\n",
      "--- Fetching Legit User Number 522---\n",
      "getting tweets before 219040229418475519\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8053012\n",
      "--- Fetching Legit User Number 523---\n",
      "getting tweets before 764207944070201343\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8053532\n",
      "--- Fetching Legit User Number 524---\n",
      "getting tweets before 848731174352670720\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8068892\n",
      "--- Fetching Legit User Number 525---\n",
      "getting tweets before 1056186731173634047\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8073812\n",
      "--- Fetching Legit User Number 526---\n",
      "getting tweets before 1051358172622049279\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8074822\n",
      "--- Fetching Legit User Number 527---\n",
      "getting tweets before 1066280292099473407\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8077952\n",
      "--- Fetching Legit User Number 528---\n",
      "getting tweets before 554248196860686335\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8078672\n",
      "--- Fetching Legit User Number 529---\n",
      "getting tweets before 610869097312686079\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8095172\n",
      "--- Fetching Legit User Number 530---\n",
      "getting tweets before 1021081421035855871\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8105772\n",
      "--- Fetching Legit User Number 531---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8123792\n",
      "--- Fetching Legit User Number 532---\n",
      "getting tweets before 880410177396244479\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8135492\n",
      "--- Fetching Legit User Number 533---\n",
      "getting tweets before 638776042560299007\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8141012\n",
      "--- Fetching Legit User Number 534---\n",
      "getting tweets before 100096906608394239\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8156282\n",
      "--- Fetching Legit User Number 535---\n",
      "getting tweets before 886565785543610368\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8156932\n",
      "--- Fetching Legit User Number 536---\n",
      "getting tweets before 905781979445989375\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8161082\n",
      "--- Fetching Legit User Number 537---\n",
      "getting tweets before 1065757590825644031\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8163442\n",
      "--- Fetching Legit User Number 538---\n",
      "getting tweets before 443771894354149375\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8167602\n",
      "--- Fetching Legit User Number 539---\n",
      "getting tweets before 1061419570466967551\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8175762\n",
      "--- Fetching Legit User Number 540---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8180982\n",
      "--- Fetching Legit User Number 541---\n",
      "getting tweets before 1039171325086973951\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8182152\n",
      "--- Fetching Legit User Number 542---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8186762\n",
      "--- Fetching Legit User Number 543---\n",
      "getting tweets before 263370800323760127\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8188252\n",
      "--- Fetching Legit User Number 544---\n",
      "getting tweets before 1043762172134862847\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8203252\n",
      "--- Fetching Legit User Number 545---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 813229198508752896\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8208492\n",
      "--- Fetching Legit User Number 546---\n",
      "getting tweets before 1059281633046478847\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8240772\n",
      "--- Fetching Legit User Number 547---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8248602\n",
      "--- Fetching Legit User Number 548---\n",
      "getting tweets before 850499743402872831\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8254252\n",
      "--- Fetching Legit User Number 549---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8257322\n",
      "--- Fetching Legit User Number 550---\n",
      "getting tweets before 436708824503042047\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8275692\n",
      "--- Fetching Legit User Number 551---\n",
      "getting tweets before 1061997737066094591\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8276062\n",
      "--- Fetching Legit User Number 552---\n",
      "getting tweets before 512504180582264831\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8282102\n",
      "--- Fetching Legit User Number 553---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8294452\n",
      "--- Fetching Legit User Number 554---\n",
      "getting tweets before 1023024970224599040\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8295232\n",
      "--- Fetching Legit User Number 555---\n",
      "getting tweets before 1014540684412403711\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8309402\n",
      "--- Fetching Legit User Number 556---\n",
      "getting tweets before 1061370012475289599\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8318052\n",
      "--- Fetching Legit User Number 557---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8328182\n",
      "--- Fetching Legit User Number 558---\n",
      "getting tweets before 193906754243936255\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8349012\n",
      "--- Fetching Legit User Number 559---\n",
      "getting tweets before 1062912698923372543\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8350872\n",
      "--- Fetching Legit User Number 560---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8359332\n",
      "--- Fetching Legit User Number 561---\n",
      "getting tweets before 217459660008071167\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8374772\n",
      "--- Fetching Legit User Number 562---\n",
      "getting tweets before 420152891102744575\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8375922\n",
      "--- Fetching Legit User Number 563---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8378752\n",
      "--- Fetching Legit User Number 564---\n",
      "getting tweets before 1046939397453533183\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8397122\n",
      "--- Fetching Legit User Number 565---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8427902\n",
      "--- Fetching Legit User Number 566---\n",
      "getting tweets before 1063483248750280704\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8446712\n",
      "--- Fetching Legit User Number 567---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8456492\n",
      "--- Fetching Legit User Number 568---\n",
      "getting tweets before 1063922694457053184\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8481222\n",
      "--- Fetching Legit User Number 569---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8486432\n",
      "--- Fetching Legit User Number 570---\n",
      "getting tweets before 1058435408072196095\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8490832\n",
      "--- Fetching Legit User Number 571---\n",
      "getting tweets before 511737508405587967\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8503472\n",
      "--- Fetching Legit User Number 572---\n",
      "getting tweets before 457522414977835007\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8539552\n",
      "--- Fetching Legit User Number 573---\n",
      "getting tweets before 1010116143955283967\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8544002\n",
      "--- Fetching Legit User Number 574---\n",
      "getting tweets before 1027919812050251775\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8548752\n",
      "--- Fetching Legit User Number 575---\n",
      "getting tweets before 955212955112693760\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8548952\n",
      "--- Fetching Legit User Number 576---\n",
      "getting tweets before 850992353590562815\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8552342\n",
      "--- Fetching Legit User Number 577---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8554652\n",
      "--- Fetching Legit User Number 578---\n",
      "getting tweets before 582044385619107839\n",
      "...198 tweets downloaded so far\n",
      "--- Fetching Legit User Number 579---\n",
      "getting tweets before 1062327115683631104\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8568192\n",
      "--- Fetching Legit User Number 580---\n",
      "getting tweets before 1064072710328770559\n",
      "...201 tweets downloaded so far\n",
      "getting tweets before 108288039075319807\n",
      "...201 tweets downloaded so far\n",
      "--- Fetching Legit User Number 581---\n",
      "getting tweets before 963683017070956543\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8608232\n",
      "--- Fetching Legit User Number 582---\n",
      "getting tweets before 523556749203480575\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8608612\n",
      "--- Fetching Legit User Number 583---\n",
      "getting tweets before 1056032658612871167\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8614192\n",
      "--- Fetching Legit User Number 584---\n",
      "getting tweets before 250953956954611711\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8619792\n",
      "--- Fetching Legit User Number 585---\n",
      "getting tweets before 1055081377752866817\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8627342\n",
      "--- Fetching Legit User Number 586---\n",
      "getting tweets before 1058743319197614080\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8639362\n",
      "--- Fetching Legit User Number 587---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8660152\n",
      "--- Fetching Legit User Number 588---\n",
      "getting tweets before 515898192823848959\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8666172\n",
      "--- Fetching Legit User Number 589---\n",
      "getting tweets before 1040966360069808127\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8666612\n",
      "--- Fetching Legit User Number 590---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 8679982\n",
      "--- Fetching Legit User Number 591---\n",
      "getting tweets before 531433238464458751\n",
      "...201 tweets downloaded so far\n",
      "getting tweets before 326205882893479935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...201 tweets downloaded so far\n",
      "--- Fetching Legit User Number 592---\n",
      "getting tweets before 1057698790453506047\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8703862\n",
      "--- Fetching Legit User Number 593---\n",
      "getting tweets before 1061633827867480064\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8705472\n",
      "--- Fetching Legit User Number 594---\n",
      "getting tweets before 709397774819729407\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8719572\n",
      "--- Fetching Legit User Number 595---\n",
      "getting tweets before 238155669809790975\n",
      "...201 tweets downloaded so far\n",
      "getting tweets before 143350687462465536\n",
      "...201 tweets downloaded so far\n",
      "--- Fetching Legit User Number 596---\n",
      "getting tweets before 1056685596570214399\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8732352\n",
      "--- Fetching Legit User Number 597---\n",
      "getting tweets before 915314674928902143\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8737532\n",
      "--- Fetching Legit User Number 598---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8740842\n",
      "--- Fetching Legit User Number 599---\n",
      "getting tweets before 1039315338419027967\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8747752\n",
      "--- Fetching Legit User Number 600---\n",
      "getting tweets before 1029741614179074047\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8763482\n",
      "--- Fetching Legit User Number 601---\n",
      "getting tweets before 1021859116636151807\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8767852\n",
      "--- Fetching Legit User Number 602---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8789632\n",
      "--- Fetching Legit User Number 603---\n",
      "getting tweets before 889604062412492802\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8821192\n",
      "--- Fetching Legit User Number 604---\n",
      "getting tweets before 364621785729212415\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8827302\n",
      "--- Fetching Legit User Number 605---\n",
      "getting tweets before 814107336159723521\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8835252\n",
      "--- Fetching Legit User Number 606---\n",
      "getting tweets before 56836951206133759\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8838312\n",
      "--- Fetching Legit User Number 607---\n",
      "getting tweets before 898664449917149183\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8858452\n",
      "--- Fetching Legit User Number 608---\n",
      "getting tweets before 926607713685164031\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8861742\n",
      "--- Fetching Legit User Number 609---\n",
      "getting tweets before 1064591826689044479\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8952542\n",
      "--- Fetching Legit User Number 610---\n",
      "getting tweets before 354370675890331649\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8974392\n",
      "--- Fetching Legit User Number 611---\n",
      "getting tweets before 537725886003302400\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 8980072\n",
      "--- Fetching Legit User Number 612---\n",
      "getting tweets before 913174178467115007\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9003212\n",
      "--- Fetching Legit User Number 613---\n",
      "getting tweets before 1052488525592096767\n",
      "...200 tweets downloaded so far\n",
      "--- Fetching Legit User Number 614---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9013332\n",
      "--- Fetching Legit User Number 615---\n",
      "getting tweets before 939195798855839744\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9014352\n",
      "--- Fetching Legit User Number 616---\n",
      "getting tweets before 727534268881084415\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9038492\n",
      "--- Fetching Legit User Number 617---\n",
      "getting tweets before 295393841006116863\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9056592\n",
      "--- Fetching Legit User Number 618---\n",
      "getting tweets before 76694769849483263\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9057432\n",
      "--- Fetching Legit User Number 619---\n",
      "getting tweets before 514087812128604159\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9058832\n",
      "--- Fetching Legit User Number 620---\n",
      "getting tweets before 863136917373804544\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9092762\n",
      "--- Fetching Legit User Number 621---\n",
      "getting tweets before 1039624319087923200\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9103722\n",
      "--- Fetching Legit User Number 622---\n",
      "getting tweets before 811159925359517695\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9103852\n",
      "--- Fetching Legit User Number 623---\n",
      "getting tweets before 1010628135572918272\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9128662\n",
      "--- Fetching Legit User Number 624---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9139022\n",
      "--- Fetching Legit User Number 625---\n",
      "getting tweets before 195813398242525183\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9140722\n",
      "--- Fetching Legit User Number 626---\n",
      "getting tweets before 1063202234589200384\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9161202\n",
      "--- Fetching Legit User Number 627---\n",
      "getting tweets before 509131789416554496\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9189862\n",
      "--- Fetching Legit User Number 628---\n",
      "getting tweets before 1021644051785961471\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9196572\n",
      "--- Fetching Legit User Number 629---\n",
      "getting tweets before 932353664429232127\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9198542\n",
      "--- Fetching Legit User Number 630---\n",
      "getting tweets before 1062759321950404607\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9207632\n",
      "--- Fetching Legit User Number 631---\n",
      "getting tweets before 1054357704536408074\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9209422\n",
      "--- Fetching Legit User Number 632---\n",
      "getting tweets before 1056937798006120447\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9228342\n",
      "--- Fetching Legit User Number 633---\n",
      "getting tweets before 136464751239761921\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9231442\n",
      "--- Fetching Legit User Number 634---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9244672\n",
      "--- Fetching Legit User Number 635---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9249352\n",
      "--- Fetching Legit User Number 636---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9263172\n",
      "--- Fetching Legit User Number 637---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1065384626737139711\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9279222\n",
      "--- Fetching Legit User Number 638---\n",
      "getting tweets before 959546225941991424\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9280282\n",
      "--- Fetching Legit User Number 639---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9287612\n",
      "--- Fetching Legit User Number 640---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9292972\n",
      "--- Fetching Legit User Number 641---\n",
      "getting tweets before 1033553261867937791\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9298152\n",
      "--- Fetching Legit User Number 642---\n",
      "getting tweets before 1022813283869503487\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9302652\n",
      "--- Fetching Legit User Number 643---\n",
      "getting tweets before 293469760937660416\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9313112\n",
      "--- Fetching Legit User Number 644---\n",
      "getting tweets before 1038292115804041215\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9318752\n",
      "--- Fetching Legit User Number 645---\n",
      "getting tweets before 883415363974778879\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9328002\n",
      "--- Fetching Legit User Number 646---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9338842\n",
      "--- Fetching Legit User Number 647---\n",
      "getting tweets before 784493896906706944\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9346172\n",
      "--- Fetching Legit User Number 648---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9408252\n",
      "--- Fetching Legit User Number 649---\n",
      "getting tweets before 137222262397992959\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9431582\n",
      "--- Fetching Legit User Number 650---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9452922\n",
      "--- Fetching Legit User Number 651---\n",
      "getting tweets before 1062093887907553282\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9460032\n",
      "--- Fetching Legit User Number 652---\n",
      "getting tweets before 1005151505178091519\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9484602\n",
      "--- Fetching Legit User Number 653---\n",
      "getting tweets before 1025962494378926079\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9499292\n",
      "--- Fetching Legit User Number 654---\n",
      "getting tweets before 19518148763\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9509312\n",
      "--- Fetching Legit User Number 655---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9510792\n",
      "--- Fetching Legit User Number 656---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9521532\n",
      "--- Fetching Legit User Number 657---\n",
      "getting tweets before 465298912824135679\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9527012\n",
      "--- Fetching Legit User Number 658---\n",
      "getting tweets before 1065008966588145663\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9532512\n",
      "--- Fetching Legit User Number 659---\n",
      "getting tweets before 970755614845603839\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9566042\n",
      "--- Fetching Legit User Number 660---\n",
      "getting tweets before 297364467602296831\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9569262\n",
      "--- Fetching Legit User Number 661---\n",
      "getting tweets before 27335068671\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9573852\n",
      "--- Fetching Legit User Number 662---\n",
      "getting tweets before 630877859901476863\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9583582\n",
      "--- Fetching Legit User Number 663---\n",
      "getting tweets before 1065562207923130369\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9587742\n",
      "--- Fetching Legit User Number 664---\n",
      "getting tweets before 1041846253951123457\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9594112\n",
      "--- Fetching Legit User Number 665---\n",
      "getting tweets before 1065174735418355711\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9608002\n",
      "--- Fetching Legit User Number 666---\n",
      "getting tweets before 672473584669999104\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9608132\n",
      "--- Fetching Legit User Number 667---\n",
      "getting tweets before 1065032902134640639\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9609372\n",
      "--- Fetching Legit User Number 668---\n",
      "getting tweets before 976161266447343615\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9626642\n",
      "--- Fetching Legit User Number 669---\n",
      "getting tweets before 1064858432258351103\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9634812\n",
      "--- Fetching Legit User Number 670---\n",
      "getting tweets before 18866939435\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9637032\n",
      "--- Fetching Legit User Number 671---\n",
      "getting tweets before 1054049181927534592\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9643542\n",
      "--- Fetching Legit User Number 672---\n",
      "getting tweets before 1055531050338828287\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9648662\n",
      "--- Fetching Legit User Number 673---\n",
      "getting tweets before 262192526889463808\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9650582\n",
      "--- Fetching Legit User Number 674---\n",
      "getting tweets before 1045437585479200767\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9655972\n",
      "--- Fetching Legit User Number 675---\n",
      "getting tweets before 165156403617599489\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9657882\n",
      "--- Fetching Legit User Number 676---\n",
      "getting tweets before 1061796076615684096\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9671202\n",
      "--- Fetching Legit User Number 677---\n",
      "getting tweets before 587957390315773951\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9677522\n",
      "--- Fetching Legit User Number 678---\n",
      "getting tweets before 978602809481408512\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9684422\n",
      "--- Fetching Legit User Number 679---\n",
      "getting tweets before 1032625371773054975\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9722452\n",
      "--- Fetching Legit User Number 680---\n",
      "getting tweets before 236398459429736447\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9772982\n",
      "--- Fetching Legit User Number 681---\n",
      "getting tweets before 1035791025422442495\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9779082\n",
      "--- Fetching Legit User Number 682---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1059834086326460415\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9782772\n",
      "--- Fetching Legit User Number 683---\n",
      "getting tweets before 10804275298\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9800782\n",
      "--- Fetching Legit User Number 684---\n",
      "getting tweets before 1052554423342260223\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9804112\n",
      "--- Fetching Legit User Number 685---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9804712\n",
      "--- Fetching Legit User Number 686---\n",
      "getting tweets before 9576612756\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9815272\n",
      "--- Fetching Legit User Number 687---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9820202\n",
      "--- Fetching Legit User Number 688---\n",
      "getting tweets before 1029170827713900543\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9841852\n",
      "--- Fetching Legit User Number 689---\n",
      "getting tweets before 644318883491508223\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9860352\n",
      "--- Fetching Legit User Number 690---\n",
      "getting tweets before 863578805239255039\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9865162\n",
      "--- Fetching Legit User Number 691---\n",
      "Exception was: Not authorized.\n",
      "Failed to load data for user 9878422\n",
      "--- Fetching Legit User Number 692---\n",
      "getting tweets before 1050543000831578111\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9880822\n",
      "--- Fetching Legit User Number 693---\n",
      "getting tweets before 681916132153016319\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9883162\n",
      "--- Fetching Legit User Number 694---\n",
      "getting tweets before 943866443044671493\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9895182\n",
      "--- Fetching Legit User Number 695---\n",
      "getting tweets before 136658709928607743\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9907912\n",
      "--- Fetching Legit User Number 696---\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9918772\n",
      "--- Fetching Legit User Number 697---\n",
      "getting tweets before 386631840637149183\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9981032\n",
      "--- Fetching Legit User Number 698---\n",
      "getting tweets before 714460335957213183\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9982862\n",
      "--- Fetching Legit User Number 699---\n",
      "getting tweets before 996090441580851202\n",
      "Exception was: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n",
      "Failed to load data for user 9988572\n"
     ]
    }
   ],
   "source": [
    "# get first 10 legit users\n",
    "for i in range(500,700):\n",
    "    print(\"--- Fetching Legit User Number {}---\".format(i))\n",
    "    get_all_tweets(legit_list[i], False)\n",
    "    #time.sleep(30)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM207_HW9_2018_Matthew-Stewart.ipynb \u001b[31mbot_users.txt\u001b[m\u001b[m\n",
      "BarackObama_tweets.csv               \u001b[34mcresci-2017.csv (1)\u001b[m\u001b[m\n",
      "LICENSE                              \u001b[34mdata_NLP\u001b[m\u001b[m\n",
      "NLP_EDA.ipynb                        elonmusk_tweets.csv\n",
      "README.md                            \u001b[31mlegitimate_users.txt\u001b[m\u001b[m\n",
      "_config.yml                          tweets.json\n",
      "['10997_tweets.csv', '1599001_tweets.csv', '4567451_tweets.csv', '7967132_tweets.csv', '6301_tweets.csv', '11228722_tweets.csv', '10836_tweets.csv']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "!ls\n",
    "mypath_bots = 'data_NLP/bots/'\n",
    "mypath_legit = 'data_NLP/legit/'\n",
    "botfiles = [f for f in listdir(mypath_bots) if isfile(join(mypath_bots, f)) and not f=='.DS_Store']\n",
    "legitfiles = [f for f in listdir(mypath_bots) if isfile(join(mypath_bots, f))and not f=='.DS_Store']\n",
    "print(legitfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1057695407344541696\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1049363997617582080\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1038332059129761792\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 1023749689701593087\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 1015854883990265855\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 1010428377797308415\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 1005875421999554559\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 1000444616536031231\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 996102919811350527\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 979895766880841732\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 960390661211021311\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 933576358793318400\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 901904930071609344\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 885626334503882751\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 872869542376030207\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 855161676705824767\n",
      "...3224 tweets downloaded so far\n",
      "getting tweets before 848415356263702527\n",
      "...3224 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets('elonmusk', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM207_HW9_2018_Matthew-Stewart.ipynb \u001b[31mbot_users.txt\u001b[m\u001b[m\r\n",
      "BarackObama_tweets.csv               \u001b[34mcresci-2017.csv (1)\u001b[m\u001b[m\r\n",
      "LICENSE                              \u001b[34mdata_NLP\u001b[m\u001b[m\r\n",
      "NLP_EDA.ipynb                        elonmusk_tweets.csv\r\n",
      "README.md                            \u001b[31mlegitimate_users.txt\u001b[m\u001b[m\r\n",
      "_config.yml                          tweets.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "\n",
    "tweets_df = pd.read_csv('elonmusk_tweets.csv')\n",
    "# change to datetime\n",
    "#tweets_df['created_at'] = pd.to_datetime(tweets_df['created_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "full_tweets =tweets_df.copy()\n",
    "#tweetsT = tweets_df['created_at']\n",
    "tweets_df = tweets_df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features of tweets (pre-cleaning data)\n",
    "\n",
    "# number of hashtags \n",
    "tweets_df['num_hashtags'] = tweets_df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "# number of all-caps words \n",
    "tweets_df['all_upper'] = tweets_df['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@margrethmpossi Varies per person, but about 80 sustained, peaking above 100 at times. Pain level increases exponentially above 80.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['text'].values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"@verge It won't matter\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tweets_df['text']))\n",
    "tweets_df['text'].values[3223]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-7ef3ce98db71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_emojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m tweets_df['emojis'] = [extract_emojis(tweet) for tweet in tweets_df['text'].values[i] \n\u001b[0m\u001b[1;32m     44\u001b[0m                        for i in range(len(tweets_df['text']))]\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#tweets_df['emojis'] =[getTweetEmoticons(text) for text in (tweets_df['text'].values[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "# deal with emojis\n",
    "\n",
    "class Emoticons:\n",
    "    POSITIVE = [\"*O\", \"*-*\", \"*O*\", \"*o*\", \"* *\",\n",
    "                \":P\", \":D\", \":d\", \":p\",\n",
    "                \";P\", \";D\", \";d\", \";p\",\n",
    "                \":-)\", \";-)\", \":=)\", \";=)\",\n",
    "                \":<)\", \":>)\", \";>)\", \";=)\",\n",
    "                \"=}\", \":)\", \"(:;)\",\n",
    "                \"(;\", \":}\", \"{:\", \";}\",\n",
    "                \"{;:]\",\n",
    "                \"[;\", \":')\", \";')\", \":-3\",\n",
    "                \"{;\", \":]\",\n",
    "                \";-3\", \":-x\", \";-x\", \":-X\",\n",
    "                \";-X\", \":-}\", \";-=}\", \":-]\",\n",
    "                \";-]\", \":-.)\",\n",
    "                \"^_^\", \"^-^\"]\n",
    "\n",
    "    NEGATIVE = [\":(\", \";(\", \":'(\",\n",
    "                \"=(\", \"={\", \"):\", \");\",\n",
    "                \")':\", \")';\", \")=\", \"}=\",\n",
    "                \";-{{\", \";-{\", \":-{{\", \":-{\",\n",
    "                \":-(\", \";-(\",\n",
    "                \":,)\", \":'{\",\n",
    "                \"[:\", \";]\"\n",
    "                ]\n",
    "\n",
    "def getTweetEmoticons(tweet):\n",
    "    print(tweet)\n",
    "    regexp = {\"SPACES\": r\"\\s+\"}\n",
    "    emoji = list()\n",
    "    for tok in re.split(ParseTweet.regexp[\"SPACES\"], tweet.strip()):\n",
    "        if tok in Emoticons.POSITIVE:\n",
    "            emoji.append(tok)\n",
    "        if tok in Emoticons.NEGATIVE:\n",
    "            emoji.append(tok)\n",
    "    return emoji\n",
    "\n",
    "# # all emojis in a text \n",
    "\n",
    "def extract_emojis(str):\n",
    "    return ''.join(c for c in str if c in emoji.UNICODE_EMOJI)\n",
    "tweets_df['emojis'] = [extract_emojis(tweet) for tweet in tweets_df['text'].values[i] \n",
    "                       for i in range(len(tweets_df['text']))]\n",
    "#tweets_df['emojis'] =[getTweetEmoticons(text) for text in (tweets_df['text'].values[i]) \n",
    "#                      for i in range(len(tweets_df['text']))]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 liters of pure water costs 1\n",
      "For those worried about running out of fresh water it may help to know that desalination only costs 01 cents per \n",
      "Ah yes fair point\n",
      "Used to live in Silicon Valley now I live in Silicone Valley\n",
      "Not yet\n"
     ]
    }
   ],
   "source": [
    "test_text = tweets_df.text[:5]\n",
    "for i in test_text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000 liters of pure water costs 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>all_upper</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000 liters of pure water costs 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For those worried about running out of fresh w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ah yes fair point</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Used to live in Silicon Valley now I live in S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not yet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trouble</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Earth is</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Earths crust is only 1 of Earth mass so techni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Earth should be called Water Our surface is 71...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yeah good idea to offer that as a setting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Contour remains approx same but fundamental ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT _Alex This is real How a space ship leaves ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT    And heres a nifty spec sheet too</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If you dont want a Tesla heres a list of all e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT  Trump administrations first report on clim...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Signing off for a while</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Happy Thanksgiving</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Starships were meant to fly</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Starship Tooters</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Good one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  num_hashtags  \\\n",
       "0                   1000 liters of pure water costs 1             0   \n",
       "1   For those worried about running out of fresh w...             0   \n",
       "2                                   Ah yes fair point             0   \n",
       "3   Used to live in Silicon Valley now I live in S...             0   \n",
       "4                                             Not yet             0   \n",
       "5                                             trouble             0   \n",
       "6                                            Earth is             0   \n",
       "7   Earths crust is only 1 of Earth mass so techni...             0   \n",
       "8   Earth should be called Water Our surface is 71...             0   \n",
       "9           Yeah good idea to offer that as a setting             0   \n",
       "10  Contour remains approx same but fundamental ma...             0   \n",
       "11  RT _Alex This is real How a space ship leaves ...             0   \n",
       "12          RT    And heres a nifty spec sheet too                0   \n",
       "13  If you dont want a Tesla heres a list of all e...             0   \n",
       "14  RT  Trump administrations first report on clim...             0   \n",
       "15                            Signing off for a while             0   \n",
       "16                                 Happy Thanksgiving             0   \n",
       "17                       Starships were meant to fly              0   \n",
       "18                                   Starship Tooters             0   \n",
       "19                                           Good one             0   \n",
       "\n",
       "    all_upper emojis  word_count  char_count  \n",
       "0           0                  7          33  \n",
       "1           0                 22         113  \n",
       "2           0                  4          17  \n",
       "3           1                 12          60  \n",
       "4           0                  2           7  \n",
       "5           0                  2           8  \n",
       "6           0                  2           8  \n",
       "7           0                 16          77  \n",
       "8           0                 19          94  \n",
       "9           0                  9          41  \n",
       "10          0                 13          90  \n",
       "11          2                 25         127  \n",
       "12          1                 14          41  \n",
       "13          0                 19          81  \n",
       "14          2                 19         118  \n",
       "15          0                  5          23  \n",
       "16          0                  2          18  \n",
       "17          0                  7          29  \n",
       "18          0                  2          16  \n",
       "19          0                  2           8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean tweets \n",
    "tweets_df['text'] = [re.sub(r'http[A-Za-z0-9:/.]+','',str(tweets_df['text'][i])) for i in range(len(tweets_df['text']))]\n",
    "removeHTML_text = [BeautifulSoup(tweets_df.text[i], 'lxml').get_text() for i in range(len(tweets_df.text))]\n",
    "tweets_df.text = removeHTML_text\n",
    "tweets_df['text'] = [re.sub(r'@[A-Za-z0-9]+','',str(tweets_df['text'][i])) for i in range(len(tweets_df['text']))]\n",
    "\n",
    "\n",
    "weird_characters_regex = re.compile(r\"[^\\w\\d ]\") \n",
    "tweets_df.text = tweets_df.text.str.replace(weird_characters_regex, \"\")\n",
    "\n",
    "\n",
    "# look at results \n",
    "display(tweets_df.text[0])\n",
    "display(tweets_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000 liters of pure water costs 1</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For those worried about running out of fresh w...</td>\n",
       "      <td>113</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ah yes fair point</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Used to live in Silicon Valley now I live in S...</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not yet</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  char_count  word_count\n",
       "0                  1000 liters of pure water costs 1          33           7\n",
       "1  For those worried about running out of fresh w...         113          22\n",
       "2                                  Ah yes fair point          17           4\n",
       "3  Used to live in Silicon Valley now I live in S...          60          12\n",
       "4                                            Not yet           7           2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text            object\n",
       "num_hashtags     int64\n",
       "all_upper        int64\n",
       "emojis          object\n",
       "word_count       int64\n",
       "char_count       int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get word coult, char count\n",
    "tweets_df['word_count'] = tweets_df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "tweets_df['char_count'] = tweets_df['text'].str.len() ## this also includes spaces\n",
    "display(tweets_df[['text','char_count','word_count']].head())\n",
    "\n",
    "# check data types \n",
    "display(tweets_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average word length\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "tweets_df['avg_word'] = tweets_df['text'].apply(lambda x: avg_word(x))\n",
    "tweets_df[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lowercase \n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "display(tweets_df['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords and punctuation\n",
    "retweet = ['RT','rt']\n",
    "stoplist = stopwords.words('english') + list(punctuation) + retweet\n",
    "#stop = stopwords.words('english')\n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stoplist))\n",
    "tweets_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment feature\n",
    "tweets_df['sentiment'] = tweets_df['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "tweets_df['polarity'] = tweets_df['text'].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "tweets_df = tweets_df.sort_values(['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tweets_df[['text','sentiment','polarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add list of nouns\n",
    "tweets_df['nouns'] = [TextBlob(tweets_df.text[i]).noun_phrases for i in range(len(tweets_df.text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['classify'] = [TextBlob(tweets_df.text[i]).noun_phrases for i in range(len(tweets_df.text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at 10 most frequent words\n",
    "freq = pd.Series(' '.join(tweets_df['text']).split()).value_counts()[:10]\n",
    "print(freq)\n",
    "\n",
    "# look at 10 least frequent words\n",
    "freq = pd.Series(' '.join(tweets_df['text']).split()).value_counts()[-20:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust spelling using TextBlob\n",
    "# run once when data are ready- takes a long time! \n",
    "#tweets_df['text'].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "TextBlob(tweets_df['text'][0]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert word to base form\n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build n-grams. That is, build some structures that often come together. For example, for Elon Musk, \"Tesla 3.\"\n",
    "# or for Trump, \"build the wall,\" etc. \n",
    "\n",
    "TextBlob(tweets_df['text'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF explained https://www.analyticsvidhya.com/blog/2015/04/information-retrieval-system-explained/\n",
    "\n",
    "# sample term frequency table\n",
    "tf1 = (tweets_df['text'][0:10]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1.sort_values(['tf', 'words'], ascending=[0, 1]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate which words appear frequently across texts -- these words don't give us much information (we,great,how,etc.)\n",
    "for i,word in enumerate(tf1['words']):\n",
    "    tf1.loc[i, 'idf'] = np.log(tweets_df.shape[0]/(len(tweets_df[tweets_df['text'].str.contains(word)])))\n",
    "display(tf1.sort_values(['idf'],ascending=[1]).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "display(tf1.sort_values(['tfidf'],ascending=[1]).head(10))\n",
    "\n",
    "# can also do this with sklearn, see code below\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "#  stop_words= 'english',ngram_range=(1,1))\n",
    "# train_vect = tfidf.fit_transform(tweets_df['text'])\n",
    "\n",
    "# train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build corpus\n",
    "corpus=[]\n",
    "a=[]\n",
    "for i in range(len(tweets_df['text'])):\n",
    "        a=tweets_df['text'][i]\n",
    "        corpus.append(a)\n",
    "        \n",
    "# look at first 5 lines        \n",
    "corpus[0:5]\n",
    "\n",
    "TEMP_FOLDER = tempfile.gettempdir()\n",
    "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))\n",
    "\n",
    "from gensim import corpora\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# remove common words and tokenize\n",
    "# uncomment and download stopwords if nessisary\n",
    "# nltk.download()\n",
    "list1 = ['RT','rt']\n",
    "stoplist = stopwords.words('english') + list(punctuation) + list1\n",
    "\n",
    "# tokenize words \n",
    "texts = [[word for word in str(document).split()] for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary of words, save it \n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save(os.path.join(TEMP_FOLDER, 'twitter.dict'))\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'twitter.mm'), corpus)  # store to disk, for lda\n",
    "\n",
    "# TfidfModel: multiplies a local component (term frequency) with a global component \n",
    "# (inverse document frequency), and normalizing the resulting documents to unit length\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "\n",
    "corpus_tfidf = tfidf[corpus]  # step 2 -- use the model to transform vectors\n",
    "\n",
    "total_topics = 5\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\n",
    "corpus_lda = lda[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "\n",
    "#Show first n important word in the topics:\n",
    "lda.show_topics(total_topics,5)\n",
    "\n",
    "data_lda = {i: OrderedDict(lda.show_topic(i,25)) for i in range(total_topics)}\n",
    "\n",
    "#made dataframe\n",
    "df_lda = pd.DataFrame(data_lda)\n",
    "print(df_lda.shape)\n",
    "df_lda = df_lda.fillna(0).T\n",
    "print(df_lda.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "g=sns.clustermap(df_lda.corr(), center=0, cmap=\"RdBu\", metric='cosine', linewidths=.75, figsize=(12, 12))\n",
    "plt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at results\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.gensim.prepare(lda, corpus_lda, dictionary, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features to explore:\n",
    "\n",
    "-Topic\n",
    "\n",
    "-Diversity of words\n",
    "\n",
    "-Diversity of topics\n",
    "\n",
    "-Word density (words/tweet)\n",
    "\n",
    "-Top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tweet activity\n",
    "\n",
    "trace = go.Histogram(\n",
    "    x=tweetsT,\n",
    "    marker=dict(\n",
    "        color='blue'\n",
    "    ),\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Tweet Activity Over Years',\n",
    "    height=450,\n",
    "    width=1200,\n",
    "    xaxis=dict(\n",
    "        title='Month and year'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Tweet Quantity'\n",
    "    ),\n",
    "    bargap=0.2,\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
