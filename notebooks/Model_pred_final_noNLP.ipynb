{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izqiUikwxuWu"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> AC209a Twitter Project - Group 15\n",
    "\n",
    "## Experiments with Twitter API\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Project Authors**: Claire Stolz, Matthew Stewart, Yiming Qin & Tianning Zhao <br>\n",
    "**Assigned Teaching Fellow**: Brandon Lee\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wp6KydtDr0vP"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# RUN THIS CELL FOR FORMAT\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-vDeBfGxuWx"
   },
   "source": [
    "### Important packages\n",
    "\n",
    "1. `Tweepy` - Twitter API - http://docs.tweepy.org/en/v3.5.0/api.html#tweepy-api-twitter-api-wrapper\n",
    "\n",
    "2. `nltk` - Natural language processing library - http://www.nltk.org/howto/twitter.html\n",
    "\n",
    "3. `twython` - Python wrapper for the Twitter API\n",
    "\n",
    "4. `jsonpickle` - converts Python objects into JSON\n",
    "\n",
    "5. `scikit-learn` - Python machine learning library\n",
    "\n",
    "https://github.com/Jefferson-Henrique/GetOldTweets-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2428,
     "status": "ok",
     "timestamp": 1543266657488,
     "user": {
      "displayName": "Yiming Qin",
      "photoUrl": "",
      "userId": "03647725801734632211"
     },
     "user_tz": 300
    },
    "id": "HoP-Iq1br0vT",
    "outputId": "4433af68-ccb7-499a-a69d-b21378bf6083"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade jsonpickle tweepy\n",
    "\n",
    "import sys\n",
    "import jsonpickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuD5S8xHr0v8"
   },
   "source": [
    "# Baseline Model  with Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_df = pd.read_csv(r\"bot_df_final.csv\",index_col='User ID')\n",
    "user_df = pd.read_csv(r\"user_df_final.csv\",index_col='User ID')\n",
    "pre_df=pd.read_csv(r\"pred_dataframe.csv\",index_col='User ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_df['bot']=1\n",
    "user_df['bot']=0\n",
    "total_df = bot_df.append(user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(total_df, test_size = 0.3, random_state=99)\n",
    "\n",
    "Y_train=train_data['bot']\n",
    "Y_test=test_data['bot']\n",
    "X_train=train_data.drop('bot',axis=1)\n",
    "X_test=test_data.drop('bot',axis=1)\n",
    "X_train = X_train.drop(['Account age (days)'], axis=1)\n",
    "X_test = X_test.drop(['Account age (days)'], axis=1)\n",
    "pre_df= pre_df.drop(['Account age (days)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4582123265569539\n",
      "0.46250691754288875\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(Y_test)/len(Y_test))\n",
    "print(np.count_nonzero(Y_train)/len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df,df_train):\n",
    "    result = df.copy()\n",
    "    for feature_name in df_train.columns:\n",
    "        max_value = df_train[feature_name].max()\n",
    "        min_value = df_train[feature_name].min()\n",
    "#         print(max_value)\n",
    "#         print(min_value)\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df=pre_df.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screen name length</th>\n",
       "      <th>Number of digits in screen name</th>\n",
       "      <th>User name length</th>\n",
       "      <th>Default profile (binary)</th>\n",
       "      <th>Default picture (binary)</th>\n",
       "      <th>Number of unique profile descriptions</th>\n",
       "      <th>Number of friends</th>\n",
       "      <th>Number of followers</th>\n",
       "      <th>Number of favorites</th>\n",
       "      <th>Number of tweets per hour</th>\n",
       "      <th>Number of tweets total</th>\n",
       "      <th>timing_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.061247</td>\n",
       "      <td>12.674833</td>\n",
       "      <td>0.643653</td>\n",
       "      <td>0.077951</td>\n",
       "      <td>2.008909</td>\n",
       "      <td>2672.840757</td>\n",
       "      <td>4880.376392</td>\n",
       "      <td>35006.447661</td>\n",
       "      <td>1.449599</td>\n",
       "      <td>42675.455457</td>\n",
       "      <td>81731.374934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.674459</td>\n",
       "      <td>1.893376</td>\n",
       "      <td>6.594908</td>\n",
       "      <td>0.479186</td>\n",
       "      <td>0.268244</td>\n",
       "      <td>1.724610</td>\n",
       "      <td>6142.131540</td>\n",
       "      <td>27176.416094</td>\n",
       "      <td>55468.272539</td>\n",
       "      <td>2.499741</td>\n",
       "      <td>75099.651500</td>\n",
       "      <td>8480.532350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13979.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>3593.250000</td>\n",
       "      <td>0.156075</td>\n",
       "      <td>4545.750000</td>\n",
       "      <td>79824.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>805.500000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>14746.500000</td>\n",
       "      <td>0.562062</td>\n",
       "      <td>17373.000000</td>\n",
       "      <td>85980.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2552.250000</td>\n",
       "      <td>2267.250000</td>\n",
       "      <td>41380.250000</td>\n",
       "      <td>1.528112</td>\n",
       "      <td>49313.000000</td>\n",
       "      <td>86337.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>59673.000000</td>\n",
       "      <td>538241.000000</td>\n",
       "      <td>507978.000000</td>\n",
       "      <td>23.337742</td>\n",
       "      <td>859699.000000</td>\n",
       "      <td>86397.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Screen name length  Number of digits in screen name  User name length  \\\n",
       "count          898.000000                       898.000000        898.000000   \n",
       "mean            11.000000                         1.061247         12.674833   \n",
       "std              2.674459                         1.893376          6.594908   \n",
       "min              4.000000                         0.000000          0.000000   \n",
       "25%              9.000000                         0.000000          8.250000   \n",
       "50%             11.000000                         0.000000         12.000000   \n",
       "75%             13.000000                         2.000000         15.000000   \n",
       "max             15.000000                        12.000000         49.000000   \n",
       "\n",
       "       Default profile (binary)  Default picture (binary)  \\\n",
       "count                898.000000                898.000000   \n",
       "mean                   0.643653                  0.077951   \n",
       "std                    0.479186                  0.268244   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    1.000000                  0.000000   \n",
       "75%                    1.000000                  0.000000   \n",
       "max                    1.000000                  1.000000   \n",
       "\n",
       "       Number of unique profile descriptions  Number of friends  \\\n",
       "count                             898.000000         898.000000   \n",
       "mean                                2.008909        2672.840757   \n",
       "std                                 1.724610        6142.131540   \n",
       "min                                 1.000000           0.000000   \n",
       "25%                                 1.000000         245.000000   \n",
       "50%                                 1.000000         805.500000   \n",
       "75%                                 2.000000        2552.250000   \n",
       "max                                13.000000       59673.000000   \n",
       "\n",
       "       Number of followers  Number of favorites  Number of tweets per hour  \\\n",
       "count           898.000000           898.000000                 898.000000   \n",
       "mean           4880.376392         35006.447661                   1.449599   \n",
       "std           27176.416094         55468.272539                   2.499741   \n",
       "min               0.000000             0.000000                   0.000161   \n",
       "25%             165.000000          3593.250000                   0.156075   \n",
       "50%             547.000000         14746.500000                   0.562062   \n",
       "75%            2267.250000         41380.250000                   1.528112   \n",
       "max          538241.000000        507978.000000                  23.337742   \n",
       "\n",
       "       Number of tweets total  timing_tweet  \n",
       "count              898.000000    898.000000  \n",
       "mean             42675.455457  81731.374934  \n",
       "std              75099.651500   8480.532350  \n",
       "min                  4.000000  13979.500000  \n",
       "25%               4545.750000  79824.062500  \n",
       "50%              17373.000000  85980.375000  \n",
       "75%              49313.000000  86337.093750  \n",
       "max             859699.000000  86397.125000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screen name length</th>\n",
       "      <th>Number of digits in screen name</th>\n",
       "      <th>User name length</th>\n",
       "      <th>Default profile (binary)</th>\n",
       "      <th>Default picture (binary)</th>\n",
       "      <th>Number of unique profile descriptions</th>\n",
       "      <th>Number of friends</th>\n",
       "      <th>Number of followers</th>\n",
       "      <th>Number of favorites</th>\n",
       "      <th>Number of tweets per hour</th>\n",
       "      <th>Number of tweets total</th>\n",
       "      <th>timing_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.00000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "      <td>7228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.674886</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.238093</td>\n",
       "      <td>0.11746</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>0.052617</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.714728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209579</td>\n",
       "      <td>0.106568</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.32199</td>\n",
       "      <td>0.144870</td>\n",
       "      <td>0.100262</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.035578</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>0.180496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.587018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.729007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.870857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Screen name length  Number of digits in screen name  User name length  \\\n",
       "count         7228.000000                      7228.000000       7228.000000   \n",
       "mean             0.674886                         0.034985          0.238093   \n",
       "std              0.209579                         0.106568          0.103235   \n",
       "min              0.000000                         0.000000          0.000000   \n",
       "25%              0.538462                         0.000000          0.173913   \n",
       "50%              0.692308                         0.000000          0.239130   \n",
       "75%              0.846154                         0.000000          0.304348   \n",
       "max              1.000000                         1.000000          1.000000   \n",
       "\n",
       "       Default profile (binary)  Default picture (binary)  \\\n",
       "count                7228.00000               7228.000000   \n",
       "mean                    0.11746                  0.021444   \n",
       "std                     0.32199                  0.144870   \n",
       "min                     0.00000                  0.000000   \n",
       "25%                     0.00000                  0.000000   \n",
       "50%                     0.00000                  0.000000   \n",
       "75%                     0.00000                  0.000000   \n",
       "max                     1.00000                  1.000000   \n",
       "\n",
       "       Number of unique profile descriptions  Number of friends  \\\n",
       "count                            7228.000000        7228.000000   \n",
       "mean                                0.052617           0.006716   \n",
       "std                                 0.100262           0.027937   \n",
       "min                                 0.000000           0.000000   \n",
       "25%                                 0.000000           0.000405   \n",
       "50%                                 0.000000           0.001066   \n",
       "75%                                 0.062500           0.003756   \n",
       "max                                 1.000000           1.000000   \n",
       "\n",
       "       Number of followers  Number of favorites  Number of tweets per hour  \\\n",
       "count          7228.000000          7228.000000                7228.000000   \n",
       "mean              0.000971             0.008639                   0.013461   \n",
       "std               0.014857             0.035578                   0.030983   \n",
       "min               0.000000             0.000000                   0.000000   \n",
       "25%               0.000013             0.000000                   0.000420   \n",
       "50%               0.000048             0.000108                   0.003439   \n",
       "75%               0.000215             0.002561                   0.013423   \n",
       "max               1.000000             1.000000                   1.000000   \n",
       "\n",
       "       Number of tweets total  timing_tweet  \n",
       "count             7228.000000   7228.000000  \n",
       "mean                 0.012956      0.714728  \n",
       "std                  0.031082      0.180496  \n",
       "min                  0.000000      0.000000  \n",
       "25%                  0.000401      0.587018  \n",
       "50%                  0.003246      0.729007  \n",
       "75%                  0.012798      0.870857  \n",
       "max                  1.000000      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled=normalize(X_train,X_train)\n",
    "X_test_scaled=normalize(X_test,X_train)\n",
    "pre_df_scaled=normalize(pre_df,X_train)\n",
    "\n",
    "pre_df_scaled.describe()\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model on training set is 0.775\n",
      "Accuracy of logistic regression model on the test set is 0.767\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000,fit_intercept=True).fit(X_train_scaled,Y_train)\n",
    "logreg_train = logreg.score(X_train_scaled, Y_train)\n",
    "#accuracy_score(Y_train,logreg.predict(X_train_scaled), normalize=True)\n",
    "print('Accuracy of logistic regression model on training set is {:.3f}'.format(logreg_train))\n",
    "# Classification error on test set\n",
    "#logreg_test = accuracy_score(logreg.predict(X_test_scaled), Y_test, normalize=True)\n",
    "logreg_test = logreg.score(X_test_scaled, Y_test)\n",
    "print('Accuracy of logistic regression model on the test set is {:.3f}'.format(logreg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_logreg= logreg.predict(pre_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial-logistic accuracy: train=80.1%, test=79.0%\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression w/ quadratic + interaction terms + regularization\n",
    "polynomial_logreg_estimator = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=True),\n",
    "    LogisticRegressionCV(multi_class=\"ovr\", penalty='l2', cv=5, max_iter=10000))\n",
    "linearLogCVpoly = polynomial_logreg_estimator.fit(X_train_scaled, Y_train)\n",
    "# Compare results\n",
    "print('Polynomial-logistic accuracy: train={:.1%}, test={:.1%}'.format(\n",
    "    linearLogCVpoly.score(X_train_scaled, Y_train), linearLogCVpoly.score(X_test_scaled, Y_test)))\n",
    "linearLogCVpoly_train = linearLogCVpoly.score(X_train_scaled, Y_train)\n",
    "linearLogCVpoly_test = linearLogCVpoly.score(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_PolyL = linearLogCVpoly.predict(pre_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7O1hHhm2r0wM"
   },
   "source": [
    "The logistic regression model does a pretty good job of separating bots from legimitate users with just two features. Once more features are used, the model should be able to predict bots with an even higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bODKODK7r0wM"
   },
   "source": [
    "## LDA and QDA Model\n",
    "\n",
    "In this section we run LDA and QDA models to classify the users into either bots or legitimate users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA accuracy train=70.1%, test: 69.9%\n",
      "QDA accuracy train=68.9%, test: 69.6%\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "lda.fit(X_train_scaled, Y_train)\n",
    "qda.fit(X_train_scaled, Y_train)\n",
    "lda.predict(X_test_scaled)\n",
    "qda.predict(X_test_scaled)\n",
    "\n",
    "print('LDA accuracy train={:.1%}, test: {:.1%}'.format(\n",
    "    lda.score(X_train_scaled, Y_train), lda.score(X_test_scaled, Y_test)))\n",
    "\n",
    "lda_train = lda.score(X_train_scaled, Y_train)\n",
    "lda_test = lda.score(X_test_scaled, Y_test)\n",
    "\n",
    "print('QDA accuracy train={:.1%}, test: {:.1%}'.format(\n",
    "    qda.score(X_train_scaled, Y_train), qda.score(X_test_scaled, Y_test)))\n",
    "\n",
    "qda_train = qda.score(X_train_scaled, Y_train)\n",
    "qda_test = qda.score(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_lda = lda.predict(pre_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_qda = qda.predict(pre_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRbPXrEWr0wS"
   },
   "source": [
    "We see here that the LDA and QDA models perform relatively well at separating this data. However, it did not perform as well as the logistic regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy train=99.3%, test: 89.4%\n"
     ]
    }
   ],
   "source": [
    "ntrees = 50\n",
    "rf = RandomForestClassifier(n_estimators=ntrees , max_depth=15, max_features='auto')\n",
    "rf.fit(X_train_scaled, Y_train)\n",
    "rf_train =rf.score(X_train_scaled, Y_train)\n",
    "rf_test =rf.score(X_test_scaled, Y_test)\n",
    "\n",
    "print('RF accuracy train={:.1%}, test: {:.1%}'.format(rf_train,rf_test))\n",
    "\n",
    "\n",
    "y_pre_df_rf = rf.predict(pre_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c1c8ebda0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Variable Importance from Random Forest')\n",
    "plt.xlabel('Relative Importance')\n",
    "pd.Series(rf.feature_importances_,index=list(X_train_scaled)).sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 23,  83,  84,  87,  95, 156, 162, 173, 195, 262, 265, 267, 290,\n",
       "        292, 305, 313, 322, 425, 461, 466, 469, 484, 538, 550, 570, 577,\n",
       "        581, 583, 590, 601, 631, 655, 688, 714, 718, 724, 725, 762, 764,\n",
       "        787, 844, 875, 891]),)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_df_rf.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=800, learning_rate=0.01)\n",
    "adaboost.fit(X_train_scaled, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.8783478541464989\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = adaboost.predict(X_test_scaled)\n",
    "pred_adaboost = [round(value) for value in y_pred_test]\n",
    "accuracy = accuracy_score(Y_test, pred_adaboost)\n",
    "print('test acc:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_adaboost = adaboost.predict(pre_df_scaled)\n",
    "np.nonzero(y_pre_df_adaboost)\n",
    "List = np.nonzero(y_pre_df_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x108531198>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Variable Importance from Adaboosting')\n",
    "plt.xlabel('Relative Importance')\n",
    "pd.Series(adaboost.feature_importances_,index=list(X_train_scaled)).sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 88.77%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "xgb = xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.01).fit(X_train_scaled, Y_train)\n",
    "y_pred_test_xgb = xgb.predict(X_test_scaled)\n",
    "accuracy_xgb = accuracy_score(Y_test, y_pred_test_xgb)\n",
    "\n",
    "\n",
    "print(\"test Accuracy: %.2f%%\" % (accuracy_xgb * 100.0))\n",
    "\n",
    "y_pre_df_xgboost = xgb.predict(pre_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x108530b38>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Variable Importance from XGBoost')\n",
    "plt.xlabel('Relative Importance')\n",
    "pd.Series(xgb.feature_importances_,index=list(X_train_scaled)).sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores_mean=[]\n",
    "scores_std=[]\n",
    "\n",
    "k_number=np.arange(1,40)\n",
    "\n",
    "for k in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    score_mean= cross_val_score(knn,X_train_scaled,Y_train,cv=5).mean()\n",
    "    score_std=cross_val_score(knn,X_train_scaled,Y_train,cv=5).std()\n",
    "    scores_mean.append(score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K= 6 with a max CV score of 0.6703148645350256\n",
      "test accuracy 0.6773152629880607\n"
     ]
    }
   ],
   "source": [
    "max_score_k=max(scores_mean)\n",
    "best_k=scores_mean.index(max(scores_mean))+1\n",
    "print('Best K=',best_k, 'with a max CV score of',max_score_k)\n",
    "\n",
    "knn_best_k = KNeighborsClassifier(n_neighbors = best_k)\n",
    "knn_best_k.fit(X_train_scaled,Y_train);\n",
    "\n",
    "pred_best_k = knn_best_k.predict(X_test_scaled)\n",
    "\n",
    "print('test accuracy',accuracy_score(Y_test, pred_best_k))\n",
    "\n",
    "knn_best_k_train = knn_best_k.score(X_train_scaled, Y_train)\n",
    "knn_best_k_test = knn_best_k.score(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_KNN = knn_best_k.predict(pre_df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJ6o10MGr0wT"
   },
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "In this section we will use a support vector machine technique to separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_plot_svm_for_c(x_train, y_train, x_test, y_test,pre_df, C):\n",
    "    # Fit SVM model\n",
    "    model = svm.SVC(C=C, kernel='linear')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Train and test error\n",
    "    tr_acc = model.score(x_train, y_train)\n",
    "    ts_acc = model.score(x_test, y_test)\n",
    "    pre_svm = model.predict(pre_df)\n",
    "    return tr_acc, ts_acc,pre_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5Y_OfuWr0wY",
    "outputId": "d5ee16e5-ced7-48df-80fb-e1f73aa5e14f"
   },
   "outputs": [],
   "source": [
    "# Fit and plot for different 'C' values\n",
    "tr_acc, ts_acc,y_pre_df_svm = fit_and_plot_svm_for_c(X_train_scaled, Y_train,X_test_scaled, Y_test, pre_df_scaled, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6473436635307139 0.6534365924491772\n"
     ]
    }
   ],
   "source": [
    "print(tr, ts_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model\n",
    "\n",
    "Model stacking is an efficient ensemble method in which the predictions, generated by using various machine learning algorithms, are used as inputs in a second-layer learning algorithm. This second-layer algorithm is trained to optimally combine the model predictions to form a new set of predictions. For example, when linear regression is used as second-layer modeling, it estimates these weights by minimizing the least square errors. However, the second-layer modeling is not restricted to only linear models; the relationship between the predictors can be more complex, opening the door to employing other machine learning algorithms.\n",
    "\n",
    "![title](modelstacking.png)\n",
    "\n",
    "Ensemble modeling and model stacking are especially popular in data science competitions, in which a sponsor posts a training set (which includes labels) and a test set (which does not include labels) and issues a global challenge to produce the best predictions of the test set for a specified performance criterion. The winning teams almost always use ensemble models instead of a single fine-tuned model. Often individual teams develop their own ensemble models in the early stages of the competition, and then join their forces in the later stages. \n",
    "\n",
    "Another popular data science competition is the KDD Cup. The following figure shows the winning solution for the 2015 competition, which used a three-stage stacked modeling approach. A similar approach will be trialed for this project to try and obtain maximal predictive capability.\n",
    "\n",
    "![title](stackedapproach.png)\n",
    "\n",
    "The figure shows that a diverse set of 64 single models were used to build the model library. These models are trained by using various machine learning algorithms. For example, the green boxes represent gradient boosting models (GBM), pink boxes represent neural network models (NN), and orange boxes represent factorization machines models (FM). You can see that there are multiple gradient boosting models in the model library; they probably vary in their use of different hyperparameter settings and/or feature sets.\n",
    "\n",
    "A simple way to enhance diversity is to train models by using different machine learning algorithms. For example, adding a factorization model to a set of tree-based models (such as random forest and gradient boosting) provides a nice diversity because a factorization model is trained very differently than decision tree models are trained. For the same machine learning algorithm, you can enhance diversity by using different hyperparameter settings and subsets of variables. If you have many features, one efficient method is to choose subsets of the variables by simple random sampling.\n",
    "\n",
    "Overfitting is an especially big problem in model stacking, because so many predictors that all predict the same target are combined. Overfitting is partially caused by this collinearity between the predictors. The most efficient techniques for training models (especially during the stacking stages) include using cross validation and some form of regularization. A good paper that outlines this procedure is [Stacked Ensemble Models for Improved Prediction Accuracy](https://support.sas.com/resources/papers/proceedings17/SAS0437-2017.pdf).\n",
    "\n",
    "That paper also shows how you can generate a diverse set of models by various methods (such as forests, gradient boosted decision trees, factorization machines, and logistic regression) and then combine them with stacked ensemble techniques such regularized regression methods, gradient boosting, and hill climbing methods.\n",
    "\n",
    "![title](levels.png)\n",
    "\n",
    "Applying stacked models to real-world big data problems can produce greater prediction accuracy and robustness than do individual models. The model stacking approach is powerful and compelling enough to alter your initial data mining mindset from finding the single best model to finding a collection of really good complementary models. Of course, this method does involve additional cost both because you need to train a large number of models and because you need to use cross validation to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model\n",
    "\n",
    "In this section we will try to implement a stacked model similar to that proposed in the \"[Stacked Ensemble Models for Improved Prediction Accuracy](https://support.sas.com/resources/papers/proceedings17/SAS0437-2017.pdf)\" paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers via Python Classes\n",
    "\n",
    "In the section of code below, we essentially write a class SklearnHelper that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn classifiers. Therefore this cuts out redundancy as won't need to write the same methods five times if we wanted to invoke five different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = X_train_scaled.shape[0]\n",
    "ntest = X_test_scaled.shape[0]\n",
    "n_pre_df=pre_df_scaled.shape[0]\n",
    "SEED = 99 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "\n",
    "kf = KFold(n_splits = NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "            print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def init :** Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n",
    "\n",
    "The rest of the code are simply methods of the class which simply call the corresponding methods already existing within the sklearn classifiers. Essentially, we have created a wrapper class to extend the various Sklearn classifiers so that this should help us reduce having to write the same code over and over when we implement multiple learners to our stacker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Fold Predictions\n",
    "\n",
    "Stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "\n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = x_train.iloc[test_index]\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating our Base First-Level Models\n",
    "\n",
    "So now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n",
    "\n",
    "- **Random Forest classifier**\n",
    "- **Extra Trees classifier**\n",
    "- **AdaBoost classifer**\n",
    "- **Gradient Boosting classifer**\n",
    "- **Support Vector Machine**\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "**n_jobs :** Number of cores used for the training process. If set to -1, all cores are used.\n",
    "\n",
    "**n_estimators :** Number of classification trees in your learning model ( set to 10 per default)\n",
    "\n",
    "**max_depth :** Maximum depth of tree, or how much a node should be expanded. Beware if set to too high a number would run the risk of overfitting as one would be growing the tree too deep\n",
    "\n",
    "**verbose :** Controls whether you want to output any text during the learning process. A value of 0 suppresses all text while a value of 3 outputs the tree learning process at every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'sigmoid',\n",
    "    'C' : 0.1\n",
    "    }\n",
    "\n",
    "logreg_params = {'C':100000, 'fit_intercept': True}\n",
    "lda_params = {'store_covariance': True}\n",
    "qda_params = {'store_covariance': True}\n",
    "polylogreg_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "logreg_stack = SklearnHelper(clf=LogisticRegression, seed=SEED, params=logreg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of the First level Predictions\n",
    "\n",
    "We now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, X_train_scaled, Y_train, X_test_scaled) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,X_train_scaled, Y_train, X_test_scaled) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X_train_scaled, Y_train, X_test_scaled) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,X_train_scaled, Y_train, X_test_scaled) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = get_oof(svc,X_train_scaled, Y_train, X_test_scaled) # Support Vector Classifier\n",
    "logreg_oof_train, logreg_oof_test = get_oof(logreg_stack,X_train_scaled, Y_train, X_test_scaled) # Linear Logistic Regression\n",
    "#lda_oof_train, lda_oof_test = get_oof(lda_stack,X_train_scaled, Y_train, X_test_scaled) # LDA\n",
    "#qda_oof_train, qda_oof_test = get_oof(qda_stack,X_train_scaled, Y_train, X_test_scaled) # QDA\n",
    "#polylogreg_oof_train, polylogreg_oof_test = get_oof(polylogreg_stack,X_train_scaled, Y_train, X_test_scaled) # Polynomial Logistic Regression\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances generated from the different classifiers\n",
    "\n",
    "Now having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n",
    "\n",
    "As per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in .featureimportances. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01656638 0.00434383 0.03600858 0.00367043 0.00089005 0.00597368\n",
      " 0.2267005  0.14966568 0.24426343 0.15633657 0.1276319  0.02794898]\n",
      "[0.27249078 0.04210205 0.19393291 0.02126333 0.00541157 0.05464063\n",
      " 0.09130192 0.0125889  0.10543186 0.06703275 0.08882293 0.04498036]\n",
      "[0.012 0.018 0.032 0.002 0.002 0.022 0.126 0.102 0.072 0.252 0.278 0.082]\n",
      "[0.03865037 0.00898988 0.05324272 0.00779129 0.00147526 0.01991401\n",
      " 0.17885627 0.17553352 0.12404804 0.14143118 0.13123649 0.11883097]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = rf.feature_importances(X_train_scaled,Y_train);\n",
    "et_feature = et.feature_importances(X_train_scaled, Y_train);\n",
    "ada_feature = ada.feature_importances(X_train_scaled, Y_train);\n",
    "gb_feature = gb.feature_importances(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature =[0.01656638, 0.00434383, 0.03600858, 0.00367043, 0.00089005, 0.00597368,\n",
    " 0.2267005,  0.14966568, 0.24426343, 0.15633657, 0.1276319,  0.02794898]\n",
    "et_feature=[0.27249078, 0.04210205, 0.19393291, 0.02126333, 0.00541157, 0.05464063,\n",
    " 0.09130192, 0.0125889,  0.10543186, 0.06703275, 0.08882293, 0.04498036]\n",
    "ada_feature =[0.012, 0.018, 0.032, 0.002, 0.002, 0.022, 0.126, 0.102, 0.072, 0.252, 0.278, 0.082]\n",
    "gb_feature=[0.03865037, 0.00898988, 0.05324272, 0.00779129, 0.00147526, 0.01991401,\n",
    " 0.17885627, 0.17553352, 0.12404804, 0.14143118, 0.13123649, 0.11883097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Screen name length', 'Number of digits in screen name',\n",
       "       'User name length', 'Default profile (binary)',\n",
       "       'Default picture (binary)',\n",
       "       'Number of unique profile descriptions', 'Number of friends',\n",
       "       'Number of followers', 'Number of favorites',\n",
       "       'Number of tweets per hour', 'Number of tweets total',\n",
       "       'timing_tweet'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Screen name length</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.272491</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.038650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of digits in screen name</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.042102</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.008990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User name length</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.193933</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.053243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Default profile (binary)</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Default picture (binary)</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of unique profile descriptions</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.054641</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of friends</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.178856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of followers</td>\n",
       "      <td>0.149666</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.175534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of favorites</td>\n",
       "      <td>0.244263</td>\n",
       "      <td>0.105432</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.124048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of tweets per hour</td>\n",
       "      <td>0.156337</td>\n",
       "      <td>0.067033</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.141431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of tweets total</td>\n",
       "      <td>0.127632</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.131236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>timing_tweet</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.118831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 features  Random Forest feature importances  \\\n",
       "0                      Screen name length                           0.016566   \n",
       "1         Number of digits in screen name                           0.004344   \n",
       "2                        User name length                           0.036009   \n",
       "3                Default profile (binary)                           0.003670   \n",
       "4                Default picture (binary)                           0.000890   \n",
       "5   Number of unique profile descriptions                           0.005974   \n",
       "6                       Number of friends                           0.226700   \n",
       "7                     Number of followers                           0.149666   \n",
       "8                     Number of favorites                           0.244263   \n",
       "9               Number of tweets per hour                           0.156337   \n",
       "10                 Number of tweets total                           0.127632   \n",
       "11                           timing_tweet                           0.027949   \n",
       "\n",
       "    Extra Trees  feature importances  AdaBoost feature importances  \\\n",
       "0                           0.272491                         0.012   \n",
       "1                           0.042102                         0.018   \n",
       "2                           0.193933                         0.032   \n",
       "3                           0.021263                         0.002   \n",
       "4                           0.005412                         0.002   \n",
       "5                           0.054641                         0.022   \n",
       "6                           0.091302                         0.126   \n",
       "7                           0.012589                         0.102   \n",
       "8                           0.105432                         0.072   \n",
       "9                           0.067033                         0.252   \n",
       "10                          0.088823                         0.278   \n",
       "11                          0.044980                         0.082   \n",
       "\n",
       "    Gradient Boost feature importances  \n",
       "0                             0.038650  \n",
       "1                             0.008990  \n",
       "2                             0.053243  \n",
       "3                             0.007791  \n",
       "4                             0.001475  \n",
       "5                             0.019914  \n",
       "6                             0.178856  \n",
       "7                             0.175534  \n",
       "8                             0.124048  \n",
       "9                             0.141431  \n",
       "10                            0.131236  \n",
       "11                            0.118831  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = X_train_scaled.columns.values\n",
    "display(cols)\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "     'Random Forest feature importances': rf_feature,\n",
    "     'Extra Trees  feature importances': et_feature,\n",
    "      'AdaBoost feature importances': ada_feature,\n",
    "    'Gradient Boost feature importances': gb_feature\n",
    "    })\n",
    "\n",
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": [
           0.01656638,
           0.00434383,
           0.03600858,
           0.00367043,
           0.00089005,
           0.00597368,
           0.2267005,
           0.14966568,
           0.24426343,
           0.15633657,
           0.1276319,
           0.02794898
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "type": "scatter",
         "uid": "8e258d6a-5ae6-441a-aa8b-1c94f4bf50d5",
         "x": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "y": [
          0.01656638,
          0.00434383,
          0.03600858,
          0.00367043,
          0.00089005,
          0.00597368,
          0.2267005,
          0.14966568,
          0.24426343,
          0.15633657,
          0.1276319,
          0.02794898
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Random Forest Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"268f4298-f069-4825-bc73-55bbaae1b7f0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"268f4298-f069-4825-bc73-55bbaae1b7f0\", [{\"marker\": {\"color\": [0.01656638, 0.00434383, 0.03600858, 0.00367043, 0.00089005, 0.00597368, 0.2267005, 0.14966568, 0.24426343, 0.15633657, 0.1276319, 0.02794898], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.01656638, 0.00434383, 0.03600858, 0.00367043, 0.00089005, 0.00597368, 0.2267005, 0.14966568, 0.24426343, 0.15633657, 0.1276319, 0.02794898], \"type\": \"scatter\", \"uid\": \"8e258d6a-5ae6-441a-aa8b-1c94f4bf50d5\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Random Forest Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"268f4298-f069-4825-bc73-55bbaae1b7f0\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"268f4298-f069-4825-bc73-55bbaae1b7f0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"268f4298-f069-4825-bc73-55bbaae1b7f0\", [{\"marker\": {\"color\": [0.01656638, 0.00434383, 0.03600858, 0.00367043, 0.00089005, 0.00597368, 0.2267005, 0.14966568, 0.24426343, 0.15633657, 0.1276319, 0.02794898], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.01656638, 0.00434383, 0.03600858, 0.00367043, 0.00089005, 0.00597368, 0.2267005, 0.14966568, 0.24426343, 0.15633657, 0.1276319, 0.02794898], \"type\": \"scatter\", \"uid\": \"8e258d6a-5ae6-441a-aa8b-1c94f4bf50d5\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Random Forest Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"268f4298-f069-4825-bc73-55bbaae1b7f0\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": [
           0.27249078,
           0.04210205,
           0.19393291,
           0.02126333,
           0.00541157,
           0.05464063,
           0.09130192,
           0.0125889,
           0.10543186,
           0.06703275,
           0.08882293,
           0.04498036
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "type": "scatter",
         "uid": "446efad8-ed60-4f06-9f87-811130a7d290",
         "x": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "y": [
          0.27249078,
          0.04210205,
          0.19393291,
          0.02126333,
          0.00541157,
          0.05464063,
          0.09130192,
          0.0125889,
          0.10543186,
          0.06703275,
          0.08882293,
          0.04498036
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Extra Trees Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"bd9ab723-a30b-44d0-8103-f31200ecbf67\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bd9ab723-a30b-44d0-8103-f31200ecbf67\", [{\"marker\": {\"color\": [0.27249078, 0.04210205, 0.19393291, 0.02126333, 0.00541157, 0.05464063, 0.09130192, 0.0125889, 0.10543186, 0.06703275, 0.08882293, 0.04498036], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.27249078, 0.04210205, 0.19393291, 0.02126333, 0.00541157, 0.05464063, 0.09130192, 0.0125889, 0.10543186, 0.06703275, 0.08882293, 0.04498036], \"type\": \"scatter\", \"uid\": \"446efad8-ed60-4f06-9f87-811130a7d290\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Extra Trees Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bd9ab723-a30b-44d0-8103-f31200ecbf67\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bd9ab723-a30b-44d0-8103-f31200ecbf67\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bd9ab723-a30b-44d0-8103-f31200ecbf67\", [{\"marker\": {\"color\": [0.27249078, 0.04210205, 0.19393291, 0.02126333, 0.00541157, 0.05464063, 0.09130192, 0.0125889, 0.10543186, 0.06703275, 0.08882293, 0.04498036], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.27249078, 0.04210205, 0.19393291, 0.02126333, 0.00541157, 0.05464063, 0.09130192, 0.0125889, 0.10543186, 0.06703275, 0.08882293, 0.04498036], \"type\": \"scatter\", \"uid\": \"446efad8-ed60-4f06-9f87-811130a7d290\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Extra Trees Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bd9ab723-a30b-44d0-8103-f31200ecbf67\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": [
           0.012,
           0.018,
           0.032,
           0.002,
           0.002,
           0.022,
           0.126,
           0.102,
           0.072,
           0.252,
           0.278,
           0.082
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "type": "scatter",
         "uid": "2184ef19-0fa6-4664-ad61-3bd079afed2f",
         "x": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "y": [
          0.012,
          0.018,
          0.032,
          0.002,
          0.002,
          0.022,
          0.126,
          0.102,
          0.072,
          0.252,
          0.278,
          0.082
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "AdaBoost Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"7811340e-bd25-4887-b9e8-7dab5e0aa206\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7811340e-bd25-4887-b9e8-7dab5e0aa206\", [{\"marker\": {\"color\": [0.012, 0.018, 0.032, 0.002, 0.002, 0.022, 0.126, 0.102, 0.072, 0.252, 0.278, 0.082], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.012, 0.018, 0.032, 0.002, 0.002, 0.022, 0.126, 0.102, 0.072, 0.252, 0.278, 0.082], \"type\": \"scatter\", \"uid\": \"2184ef19-0fa6-4664-ad61-3bd079afed2f\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"AdaBoost Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"7811340e-bd25-4887-b9e8-7dab5e0aa206\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7811340e-bd25-4887-b9e8-7dab5e0aa206\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7811340e-bd25-4887-b9e8-7dab5e0aa206\", [{\"marker\": {\"color\": [0.012, 0.018, 0.032, 0.002, 0.002, 0.022, 0.126, 0.102, 0.072, 0.252, 0.278, 0.082], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.012, 0.018, 0.032, 0.002, 0.002, 0.022, 0.126, 0.102, 0.072, 0.252, 0.278, 0.082], \"type\": \"scatter\", \"uid\": \"2184ef19-0fa6-4664-ad61-3bd079afed2f\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"AdaBoost Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"7811340e-bd25-4887-b9e8-7dab5e0aa206\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": [
           0.03865037,
           0.00898988,
           0.05324272,
           0.00779129,
           0.00147526,
           0.01991401,
           0.17885627,
           0.17553352,
           0.12404804,
           0.14143118,
           0.13123649,
           0.11883097
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "type": "scatter",
         "uid": "54da815c-2e8a-4ac6-9b69-eca11c4fce38",
         "x": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "y": [
          0.03865037,
          0.00898988,
          0.05324272,
          0.00779129,
          0.00147526,
          0.01991401,
          0.17885627,
          0.17553352,
          0.12404804,
          0.14143118,
          0.13123649,
          0.11883097
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Gradient Boosting Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"af150bd4-1883-4c60-8064-fec8556877b8\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"af150bd4-1883-4c60-8064-fec8556877b8\", [{\"marker\": {\"color\": [0.03865037, 0.00898988, 0.05324272, 0.00779129, 0.00147526, 0.01991401, 0.17885627, 0.17553352, 0.12404804, 0.14143118, 0.13123649, 0.11883097], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.03865037, 0.00898988, 0.05324272, 0.00779129, 0.00147526, 0.01991401, 0.17885627, 0.17553352, 0.12404804, 0.14143118, 0.13123649, 0.11883097], \"type\": \"scatter\", \"uid\": \"54da815c-2e8a-4ac6-9b69-eca11c4fce38\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Gradient Boosting Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"af150bd4-1883-4c60-8064-fec8556877b8\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"af150bd4-1883-4c60-8064-fec8556877b8\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"af150bd4-1883-4c60-8064-fec8556877b8\", [{\"marker\": {\"color\": [0.03865037, 0.00898988, 0.05324272, 0.00779129, 0.00147526, 0.01991401, 0.17885627, 0.17553352, 0.12404804, 0.14143118, 0.13123649, 0.11883097], \"colorscale\": \"Portland\", \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.03865037, 0.00898988, 0.05324272, 0.00779129, 0.00147526, 0.01991401, 0.17885627, 0.17553352, 0.12404804, 0.14143118, 0.13123649, 0.11883097], \"type\": \"scatter\", \"uid\": \"54da815c-2e8a-4ac6-9b69-eca11c4fce38\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Gradient Boosting Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"af150bd4-1883-4c60-8064-fec8556877b8\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['Random Forest feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['Random Forest feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Random Forest Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')\n",
    "\n",
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['Extra Trees  feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['Extra Trees  feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Extra Trees Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')\n",
    "\n",
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['AdaBoost feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['AdaBoost feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'AdaBoost Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')\n",
    "\n",
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['Gradient Boost feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['Gradient Boost feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Gradient Boosting Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Screen name length</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.272491</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.084927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of digits in screen name</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.042102</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.018359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User name length</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.193933</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.053243</td>\n",
       "      <td>0.078796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          features  Random Forest feature importances  \\\n",
       "0               Screen name length                           0.016566   \n",
       "1  Number of digits in screen name                           0.004344   \n",
       "2                 User name length                           0.036009   \n",
       "\n",
       "   Extra Trees  feature importances  AdaBoost feature importances  \\\n",
       "0                          0.272491                         0.012   \n",
       "1                          0.042102                         0.018   \n",
       "2                          0.193933                         0.032   \n",
       "\n",
       "   Gradient Boost feature importances      mean  \n",
       "0                            0.038650  0.084927  \n",
       "1                            0.008990  0.018359  \n",
       "2                            0.053243  0.078796  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column containing the average of values\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly Barplot of Average Feature Importances\n",
    "\n",
    "Having obtained the mean feature importance across all our classifiers, we can plot them into a Plotly bar plot as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": [
           0.0849268825,
           0.01835894,
           0.0787960525,
           0.0086812625,
           0.0024442199999999996,
           0.025632079999999998,
           0.1557146725,
           0.10994702499999999,
           0.1364358325,
           0.154200125,
           0.15642283,
           0.0684400775
          ],
          "colorscale": "Portland",
          "reversescale": false,
          "showscale": true
         },
         "opacity": 0.6,
         "type": "bar",
         "uid": "7ef1ddb9-a7e8-49db-ae88-e6ad403befe3",
         "width": 0.5,
         "x": [
          "Screen name length",
          "Number of digits in screen name",
          "User name length",
          "Default profile (binary)",
          "Default picture (binary)",
          "Number of unique profile descriptions",
          "Number of friends",
          "Number of followers",
          "Number of favorites",
          "Number of tweets per hour",
          "Number of tweets total",
          "timing_tweet"
         ],
         "y": [
          0.0849268825,
          0.01835894,
          0.0787960525,
          0.0086812625,
          0.0024442199999999996,
          0.025632079999999998,
          0.1557146725,
          0.10994702499999999,
          0.1364358325,
          0.154200125,
          0.15642283,
          0.0684400775
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Barplots of Mean Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"afe00824-edf5-44eb-bc58-a912950e4bd1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"afe00824-edf5-44eb-bc58-a912950e4bd1\", [{\"marker\": {\"color\": [0.0849268825, 0.01835894, 0.0787960525, 0.0086812625, 0.0024442199999999996, 0.025632079999999998, 0.1557146725, 0.10994702499999999, 0.1364358325, 0.154200125, 0.15642283, 0.0684400775], \"colorscale\": \"Portland\", \"reversescale\": false, \"showscale\": true}, \"opacity\": 0.6, \"width\": 0.5, \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.0849268825, 0.01835894, 0.0787960525, 0.0086812625, 0.0024442199999999996, 0.025632079999999998, 0.1557146725, 0.10994702499999999, 0.1364358325, 0.154200125, 0.15642283, 0.0684400775], \"type\": \"bar\", \"uid\": \"7ef1ddb9-a7e8-49db-ae88-e6ad403befe3\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Barplots of Mean Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"afe00824-edf5-44eb-bc58-a912950e4bd1\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"afe00824-edf5-44eb-bc58-a912950e4bd1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"afe00824-edf5-44eb-bc58-a912950e4bd1\", [{\"marker\": {\"color\": [0.0849268825, 0.01835894, 0.0787960525, 0.0086812625, 0.0024442199999999996, 0.025632079999999998, 0.1557146725, 0.10994702499999999, 0.1364358325, 0.154200125, 0.15642283, 0.0684400775], \"colorscale\": \"Portland\", \"reversescale\": false, \"showscale\": true}, \"opacity\": 0.6, \"width\": 0.5, \"x\": [\"Screen name length\", \"Number of digits in screen name\", \"User name length\", \"Default profile (binary)\", \"Default picture (binary)\", \"Number of unique profile descriptions\", \"Number of friends\", \"Number of followers\", \"Number of favorites\", \"Number of tweets per hour\", \"Number of tweets total\", \"timing_tweet\"], \"y\": [0.0849268825, 0.01835894, 0.0787960525, 0.0086812625, 0.0024442199999999996, 0.025632079999999998, 0.1557146725, 0.10994702499999999, 0.1364358325, 0.154200125, 0.15642283, 0.0684400775], \"type\": \"bar\", \"uid\": \"7ef1ddb9-a7e8-49db-ae88-e6ad403befe3\"}], {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"title\": \"Barplots of Mean Feature Importance\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"afe00824-edf5-44eb-bc58-a912950e4bd1\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = feature_dataframe['mean'].values\n",
    "x = feature_dataframe['features'].values\n",
    "data = [go.Bar(\n",
    "            x= x,\n",
    "             y= y,\n",
    "            width = 0.5,\n",
    "            marker=dict(\n",
    "               color = feature_dataframe['mean'].values,\n",
    "            colorscale='Portland',\n",
    "            showscale=True,\n",
    "            reversescale = False\n",
    "            ),\n",
    "            opacity=0.6\n",
    "        )]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Barplots of Mean Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='bar-direct-labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-Level Predictions from the First-level Output\n",
    "\n",
    "### First-level output as new features\n",
    "\n",
    "Having now obtained our first-level predictions, one can think of it as essentially building a new set of features to be used as training data for the next classifier. As per the code below, we are therefore having as our new columns the first-level predictions from our earlier classifiers and we train the next classifier on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest  ExtraTrees  AdaBoost  GradientBoost  Logistic Regression\n",
       "0           0.0         0.0       0.0            0.0                  0.0\n",
       "1           0.0         0.0       0.0            0.0                  0.0\n",
       "2           0.0         0.0       0.0            0.0                  0.0\n",
       "3           0.0         0.0       0.0            0.0                  0.0\n",
       "4           0.0         0.0       0.0            0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest  ExtraTrees  AdaBoost  GradientBoost  Logistic Regression\n",
       "0           0.0         0.0       0.0            0.0                  0.0\n",
       "1           1.0         1.0       1.0            1.0                  1.0\n",
       "2           0.0         0.0       0.0            0.0                  0.0\n",
       "3           1.0         0.0       0.8            0.4                  0.0\n",
       "4           0.0         0.0       0.0            0.0                  0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel(),\n",
    "        'Logistic Regression': logreg_oof_train.ravel()\n",
    "    })\n",
    "display(base_predictions_train.head())\n",
    "\n",
    "base_predictions_test = pd.DataFrame( {'RandomForest': rf_oof_test.ravel(),\n",
    "     'ExtraTrees': et_oof_test.ravel(),\n",
    "     'AdaBoost': ada_oof_test.ravel(),\n",
    "      'GradientBoost': gb_oof_test.ravel(),\n",
    "        'Logistic Regression': logreg_oof_test.ravel()\n",
    "    })\n",
    "base_predictions_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap of the Second Level Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "colorscale": "Viridis",
         "reversescale": true,
         "showscale": true,
         "type": "heatmap",
         "uid": "438ea121-f278-44b1-bee8-404b2e45b179",
         "x": [
          "RandomForest",
          "ExtraTrees",
          "AdaBoost",
          "GradientBoost",
          "Logistic Regression"
         ],
         "y": [
          "RandomForest",
          "ExtraTrees",
          "AdaBoost",
          "GradientBoost",
          "Logistic Regression"
         ],
         "z": [
          [
           1,
           0.45269433899780304,
           0.8381459442589221,
           0.880091848129321,
           0.6041201277236143
          ],
          [
           0.45269433899780304,
           1,
           0.463943222507909,
           0.43817069932426195,
           0.6497239436567502
          ],
          [
           0.8381459442589221,
           0.463943222507909,
           1,
           0.8226895117448115,
           0.6180032462724757
          ],
          [
           0.880091848129321,
           0.43817069932426195,
           0.8226895117448115,
           1,
           0.5898879241810507
          ],
          [
           0.6041201277236143,
           0.6497239436567502,
           0.6180032462724757,
           0.5898879241810507,
           1
          ]
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\", [{\"colorscale\": \"Viridis\", \"reversescale\": true, \"showscale\": true, \"x\": [\"RandomForest\", \"ExtraTrees\", \"AdaBoost\", \"GradientBoost\", \"Logistic Regression\"], \"y\": [\"RandomForest\", \"ExtraTrees\", \"AdaBoost\", \"GradientBoost\", \"Logistic Regression\"], \"z\": [[1.0, 0.45269433899780304, 0.8381459442589221, 0.880091848129321, 0.6041201277236143], [0.45269433899780304, 1.0, 0.463943222507909, 0.43817069932426195, 0.6497239436567502], [0.8381459442589221, 0.463943222507909, 1.0, 0.8226895117448115, 0.6180032462724757], [0.880091848129321, 0.43817069932426195, 0.8226895117448115, 1.0, 0.5898879241810507], [0.6041201277236143, 0.6497239436567502, 0.6180032462724757, 0.5898879241810507, 1.0]], \"type\": \"heatmap\", \"uid\": \"b9f66f04-79b7-4cf0-aa34-574ea3068f36\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\", [{\"colorscale\": \"Viridis\", \"reversescale\": true, \"showscale\": true, \"x\": [\"RandomForest\", \"ExtraTrees\", \"AdaBoost\", \"GradientBoost\", \"Logistic Regression\"], \"y\": [\"RandomForest\", \"ExtraTrees\", \"AdaBoost\", \"GradientBoost\", \"Logistic Regression\"], \"z\": [[1.0, 0.45269433899780304, 0.8381459442589221, 0.880091848129321, 0.6041201277236143], [0.45269433899780304, 1.0, 0.463943222507909, 0.43817069932426195, 0.6497239436567502], [0.8381459442589221, 0.463943222507909, 1.0, 0.8226895117448115, 0.6180032462724757], [0.880091848129321, 0.43817069932426195, 0.8226895117448115, 1.0, 0.5898879241810507], [0.6041201277236143, 0.6497239436567502, 0.6180032462724757, 0.5898879241810507, 1.0]], \"type\": \"heatmap\", \"uid\": \"b9f66f04-79b7-4cf0-aa34-574ea3068f36\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"32eb9ef1-229e-4ffe-8536-acb162b7fa12\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= base_predictions_train.astype(float).corr().values ,\n",
    "        x=base_predictions_train.columns.values,\n",
    "        y= base_predictions_train.columns.values,\n",
    "          colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            reversescale = True\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.concatenate((0.4*ada_oof_train, 0.2*svc_oof_train, 0.2*rf_oof_train, 0.35*logreg_oof_train), axis=1)\n",
    "x_test = np.concatenate((0.4*ada_oof_test, 0.2*svc_oof_test, 0.2*rf_oof_test, 0.35*logreg_oof_test), axis=1)\n",
    "x_train = x_train.mean(axis=1).reshape(-1,1)\n",
    "x_test = x_test.mean(axis=1).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There have been quite a few articles and Kaggle competition winner stories about the merits of having trained models that are more uncorrelated with one another producing better scores. Having now concatenated and joined both the first-level train and test predictions as x_train and x_test, we can now fit a second-level learning model.\n",
    "\n",
    "### Second level learning model via XGBoost\n",
    "\n",
    "Here we choose the eXtremely famous library for boosted tree learning model, XGBoost. It was built to optimize large-scale boosted tree algorithms. For further information about the algorithm, check out the official documentation.\n",
    "\n",
    "Anyways, we call an XGBClassifier and fit it to the first-level train and target data and use the learned model to predict the test data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBClassifier(\n",
    "    learning_rate = 0.001,\n",
    " n_estimators= 1000,\n",
    " max_depth= 5,\n",
    " min_child_weight= 1,\n",
    " gamma=0.8,                      \n",
    " subsample=0.7,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:hinge',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, Y_train)\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick run down of the XGBoost parameters used in the model:\n",
    "\n",
    "**max_depth :** How deep you want to grow your tree. Beware if set to too high a number might run the risk of overfitting.\n",
    "\n",
    "**gamma :** minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.\n",
    "\n",
    "**eta :** step size shrinkage used in each boosting step to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_train = gbm.score(x_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending\n",
    "\n",
    "In this section we utilize the `mlens` package to develop a blended ensemble with 3 layers and more than 20 different classification techniques in order to achieve a truly superior predictive capability to the previous models. The blended model is also surprisingly fast given that it contains so many different methods, including many not previously discussed in AC209a such as gaussian process classifiers, MLP classifiers, extremely randomized tree classifiers, naive Bayes classifiers, and more.\n",
    "\n",
    "The purpose of showing the blended model is to see what happens when you (quite literally) throw everything you have at the problem and see how well you do. In this case, we do surprisingly well, but trying to optimize the hyperparameters of this model would be a truly daunting task, and there is essentially no interpretability in this model. It is purely to obtain maximal accuracy for the given input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from mlens.ensemble import BlendEnsemble\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ensemble = BlendEnsemble()\n",
    "ensemble.add([SVR(C=.1), RandomForestClassifier(n_estimators=200, random_state=SEED), LogisticRegression(C=1),  ExtraTreesClassifier(max_depth=10,random_state=SEED), GradientBoostingClassifier(random_state=SEED), AdaBoostClassifier(random_state=SEED)])\n",
    "#ensemble.add([SVC(C=1),GaussianProcessClassifier(random_state=SEED),LogisticRegression(C=1000000), GradientBoostingClassifier(random_state=SEED), AdaBoostClassifier(random_state=SEED)])\n",
    "#ensemble.add([ RandomForestClassifier(n_estimators=100, random_state=SEED), GradientBoostingClassifier(random_state=SEED),GaussianProcessClassifier(random_state=SEED)])\n",
    "#ensemble.add([SVC(C=1), AdaBoostClassifier(random_state=SEED)])\n",
    "ensemble.add([xgb.XGBClassifier(random_state=SEED), RandomForestClassifier(n_estimators=200, random_state=SEED), GradientBoostingClassifier(random_state=SEED)])\n",
    "ensemble.add_meta(xgb.XGBClassifier(random_state=SEED))\n",
    "\n",
    "ensemble.fit(X_train_scaled, Y_train)\n",
    "preds = ensemble.predict(pre_df_scaled)\n",
    "ensemble_train = accuracy_score(Y_train, ensemble.predict(X_train_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Models\n",
    "\n",
    "The following dataframe shows each of the tested models and its corresponding accuracy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance comparison of the six methods:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear LR</th>\n",
       "      <td>0.775411</td>\n",
       "      <td>0.776148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial LR</th>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.808937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.913520</td>\n",
       "      <td>0.993774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.718296</td>\n",
       "      <td>0.772690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.707648</td>\n",
       "      <td>0.705728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.711197</td>\n",
       "      <td>0.708080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.945789</td>\n",
       "      <td>0.987548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.936359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking (2nd-Level Model)</th>\n",
       "      <td>0.928687</td>\n",
       "      <td>0.935667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blending (3rd-Level Model)</th>\n",
       "      <td>0.947402</td>\n",
       "      <td>0.954759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            test accuracy  training accuracy\n",
       "Linear LR                        0.775411           0.776148\n",
       "Polynomial LR                    0.800581           0.808937\n",
       "Random Forest                    0.913520           0.993774\n",
       "kNN                              0.718296           0.772690\n",
       "LDA                              0.707648           0.705728\n",
       "QDA                              0.711197           0.708080\n",
       "AdaBoost                         0.945789           0.987548\n",
       "XGBoost                          0.922233           0.936359\n",
       "Stacking (2nd-Level Model)       0.928687           0.935667\n",
       "Blending (3rd-Level Model)       0.947402           0.954759"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_var = {#\"training time\": [dec_1_fit_time,random_1_fit_time,model_1_fit_time,model_xg1_fit_time,clf_1_fit_time,cat_1_fit_time],\n",
    "            #\"inference time\": [dec_1_predict_time,random_1_predict_time,model_1_predict_time,model_xg1_predict_time,clf_1_predict_time,cat_1_predict_time],\n",
    "            \"test accuracy\": [logreg_test, linearLogCVpoly_test, rf_test, knn_best_k_test ,lda_test,qda_test, adaboost_test, xgb_test, gbm_test, ensemble_test],\n",
    "            \"training accuracy\": [logreg_train, linearLogCVpoly_train, rf_train, knn_best_k_train ,lda_train,qda_train, adaboost_train, xgb_train, gbm_train, ensemble_train],\n",
    "            #\"Cross validation\": ['No','No','No','No','No','No']\n",
    "           }\n",
    "print(\"Performance comparison of the six methods:\")\n",
    "df_var = pd.DataFrame.from_dict(dict_var)\n",
    "df_var.index= ['Linear LR', 'Polynomial LR', 'Random Forest', 'kNN', 'LDA', 'QDA', 'AdaBoost', 'XGBoost', 'Stacking (2nd-Level Model)', 'Blending (3rd-Level Model)']\n",
    "display(df_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b417291278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "xx = range(len(df_var))\n",
    "index_name=df_var.index\n",
    "plt.bar(xx, df_var['test accuracy'], color='black', alpha=0.5)\n",
    "plt.ylim(0.7,1)\n",
    "plt.title('Model Comparison on Test Set', fontsize=18)\n",
    "plt.ylabel('Test Accuracy (%)', fontsize=16)\n",
    "plt.xticks(xx,index_name,rotation=90,fontsize = 16);\n",
    "sns.despine()\n",
    "\n",
    "plt.axhline(0.95, c='k', linewidth=3, linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted stacked model performed the best on the test set, achieving an accuracy of 85.7%, a value more than 1% higher than that achieved by the other best models: logistic regression and random forest. With extra tuning of hyperparameters and model weightings it is likely that this could be increased further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netrual network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n",
      "/Users/yiming/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               6500      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 157,101\n",
      "Trainable params: 157,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_NN = models.Sequential()\n",
    "\n",
    "model_NN.add(layers.Dense(500, input_shape=(X_train_scaled.shape[1],),\n",
    "                activation='relu'))\n",
    "\n",
    "model_NN.add(layers.Dense(300, input_shape=(X_train_scaled.shape[1],),\n",
    "                activation='relu', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_NN.add(Dropout(0.5))\n",
    "          \n",
    "\n",
    "\n",
    "model_NN.add(layers.Dense(1,  \n",
    "                activation='sigmoid')) \n",
    "\n",
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model_NN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5782 samples, validate on 1446 samples\n",
      "Epoch 1/500\n",
      "5782/5782 [==============================] - 1s 160us/step - loss: 2.5321 - acc: 0.5541 - val_loss: 1.2442 - val_acc: 0.6079\n",
      "Epoch 2/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.8989 - acc: 0.6119 - val_loss: 0.7260 - val_acc: 0.5664\n",
      "Epoch 3/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.6683 - acc: 0.6446 - val_loss: 0.6584 - val_acc: 0.6335\n",
      "Epoch 4/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.6328 - acc: 0.6740 - val_loss: 0.6290 - val_acc: 0.6604\n",
      "Epoch 5/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.6132 - acc: 0.6937 - val_loss: 0.6197 - val_acc: 0.6667\n",
      "Epoch 6/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.6047 - acc: 0.7004 - val_loss: 0.6130 - val_acc: 0.6916\n",
      "Epoch 7/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5958 - acc: 0.7053 - val_loss: 0.6210 - val_acc: 0.6646\n",
      "Epoch 8/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.5912 - acc: 0.7093 - val_loss: 0.6135 - val_acc: 0.6916\n",
      "Epoch 9/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.5791 - acc: 0.7181 - val_loss: 0.5886 - val_acc: 0.7068\n",
      "Epoch 10/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.5727 - acc: 0.7271 - val_loss: 0.5982 - val_acc: 0.7082\n",
      "Epoch 11/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.5696 - acc: 0.7299 - val_loss: 0.5823 - val_acc: 0.7075\n",
      "Epoch 12/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5633 - acc: 0.7343 - val_loss: 0.5823 - val_acc: 0.7178\n",
      "Epoch 13/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.5582 - acc: 0.7421 - val_loss: 0.5817 - val_acc: 0.7185\n",
      "Epoch 14/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.5555 - acc: 0.7390 - val_loss: 0.5734 - val_acc: 0.7310\n",
      "Epoch 15/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.5504 - acc: 0.7468 - val_loss: 0.5767 - val_acc: 0.7261\n",
      "Epoch 16/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.5440 - acc: 0.7478 - val_loss: 0.5620 - val_acc: 0.7289\n",
      "Epoch 17/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.5407 - acc: 0.7542 - val_loss: 0.5575 - val_acc: 0.7400\n",
      "Epoch 18/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.5408 - acc: 0.7513 - val_loss: 0.5570 - val_acc: 0.7310\n",
      "Epoch 19/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.5381 - acc: 0.7556 - val_loss: 0.5493 - val_acc: 0.7358\n",
      "Epoch 20/500\n",
      "5782/5782 [==============================] - 0s 60us/step - loss: 0.5293 - acc: 0.7596 - val_loss: 0.5500 - val_acc: 0.7448\n",
      "Epoch 21/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.5279 - acc: 0.7606 - val_loss: 0.5565 - val_acc: 0.7407\n",
      "Epoch 22/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5244 - acc: 0.7679 - val_loss: 0.5431 - val_acc: 0.7441\n",
      "Epoch 23/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.5207 - acc: 0.7613 - val_loss: 0.5528 - val_acc: 0.7289\n",
      "Epoch 24/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5206 - acc: 0.7660 - val_loss: 0.5383 - val_acc: 0.7455\n",
      "Epoch 25/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.5187 - acc: 0.7663 - val_loss: 0.5385 - val_acc: 0.7566\n",
      "Epoch 26/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5133 - acc: 0.7745 - val_loss: 0.5353 - val_acc: 0.7510\n",
      "Epoch 27/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.5182 - acc: 0.7696 - val_loss: 0.5261 - val_acc: 0.7531\n",
      "Epoch 28/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.5154 - acc: 0.7714 - val_loss: 0.5265 - val_acc: 0.7538\n",
      "Epoch 29/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.5109 - acc: 0.7752 - val_loss: 0.5244 - val_acc: 0.7538\n",
      "Epoch 30/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.5079 - acc: 0.7774 - val_loss: 0.5307 - val_acc: 0.7580\n",
      "Epoch 31/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.5070 - acc: 0.7714 - val_loss: 0.5224 - val_acc: 0.7628\n",
      "Epoch 32/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4995 - acc: 0.7814 - val_loss: 0.5263 - val_acc: 0.7586\n",
      "Epoch 33/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.5026 - acc: 0.7793 - val_loss: 0.5258 - val_acc: 0.7628\n",
      "Epoch 34/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4978 - acc: 0.7833 - val_loss: 0.5170 - val_acc: 0.7600\n",
      "Epoch 35/500\n",
      "5782/5782 [==============================] - 0s 83us/step - loss: 0.4957 - acc: 0.7840 - val_loss: 0.5178 - val_acc: 0.7614\n",
      "Epoch 36/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.5014 - acc: 0.7800 - val_loss: 0.5434 - val_acc: 0.7434\n",
      "Epoch 37/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.5020 - acc: 0.7776 - val_loss: 0.5129 - val_acc: 0.7683\n",
      "Epoch 38/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4909 - acc: 0.7871 - val_loss: 0.5130 - val_acc: 0.7752\n",
      "Epoch 39/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4928 - acc: 0.7871 - val_loss: 0.5072 - val_acc: 0.7718\n",
      "Epoch 40/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4862 - acc: 0.7869 - val_loss: 0.5056 - val_acc: 0.7649\n",
      "Epoch 41/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4885 - acc: 0.7845 - val_loss: 0.5136 - val_acc: 0.7621\n",
      "Epoch 42/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4856 - acc: 0.7906 - val_loss: 0.5025 - val_acc: 0.7718\n",
      "Epoch 43/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4847 - acc: 0.7878 - val_loss: 0.5001 - val_acc: 0.7690\n",
      "Epoch 44/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.4784 - acc: 0.7990 - val_loss: 0.5104 - val_acc: 0.7649\n",
      "Epoch 45/500\n",
      "5782/5782 [==============================] - 0s 83us/step - loss: 0.4857 - acc: 0.7902 - val_loss: 0.5312 - val_acc: 0.7683\n",
      "Epoch 46/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4806 - acc: 0.7966 - val_loss: 0.4953 - val_acc: 0.7842\n",
      "Epoch 47/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4838 - acc: 0.7947 - val_loss: 0.5131 - val_acc: 0.7759\n",
      "Epoch 48/500\n",
      "5782/5782 [==============================] - 0s 79us/step - loss: 0.4816 - acc: 0.7925 - val_loss: 0.4908 - val_acc: 0.7815\n",
      "Epoch 49/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.4779 - acc: 0.7930 - val_loss: 0.4912 - val_acc: 0.7815\n",
      "Epoch 50/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4812 - acc: 0.7966 - val_loss: 0.5104 - val_acc: 0.7780\n",
      "Epoch 51/500\n",
      "5782/5782 [==============================] - 0s 84us/step - loss: 0.4756 - acc: 0.8013 - val_loss: 0.4954 - val_acc: 0.7801\n",
      "Epoch 52/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4714 - acc: 0.8018 - val_loss: 0.4902 - val_acc: 0.7856\n",
      "Epoch 53/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.4710 - acc: 0.8011 - val_loss: 0.4985 - val_acc: 0.7766\n",
      "Epoch 54/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4699 - acc: 0.8021 - val_loss: 0.4887 - val_acc: 0.7856\n",
      "Epoch 55/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4676 - acc: 0.8021 - val_loss: 0.4862 - val_acc: 0.7849\n",
      "Epoch 56/500\n",
      "5782/5782 [==============================] - 0s 82us/step - loss: 0.4690 - acc: 0.8056 - val_loss: 0.4823 - val_acc: 0.7822\n",
      "Epoch 57/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4627 - acc: 0.8049 - val_loss: 0.4998 - val_acc: 0.7794\n",
      "Epoch 58/500\n",
      "5782/5782 [==============================] - 0s 81us/step - loss: 0.4713 - acc: 0.8018 - val_loss: 0.5021 - val_acc: 0.7863\n",
      "Epoch 59/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4723 - acc: 0.8028 - val_loss: 0.4835 - val_acc: 0.7849\n",
      "Epoch 60/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.4636 - acc: 0.8054 - val_loss: 0.4808 - val_acc: 0.7953\n",
      "Epoch 61/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4625 - acc: 0.8077 - val_loss: 0.4773 - val_acc: 0.7877\n",
      "Epoch 62/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4604 - acc: 0.8087 - val_loss: 0.4862 - val_acc: 0.7884\n",
      "Epoch 63/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4730 - acc: 0.8016 - val_loss: 0.4917 - val_acc: 0.7856\n",
      "Epoch 64/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.4563 - acc: 0.8136 - val_loss: 0.4762 - val_acc: 0.7925\n",
      "Epoch 65/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.4580 - acc: 0.8117 - val_loss: 0.4897 - val_acc: 0.7787\n",
      "Epoch 66/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4610 - acc: 0.8123 - val_loss: 0.4802 - val_acc: 0.7863\n",
      "Epoch 67/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4555 - acc: 0.8098 - val_loss: 0.4687 - val_acc: 0.8008\n",
      "Epoch 68/500\n",
      "5782/5782 [==============================] - 0s 56us/step - loss: 0.4591 - acc: 0.8096 - val_loss: 0.4891 - val_acc: 0.7981\n",
      "Epoch 69/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.4547 - acc: 0.8139 - val_loss: 0.4708 - val_acc: 0.7960\n",
      "Epoch 70/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.4546 - acc: 0.8127 - val_loss: 0.4741 - val_acc: 0.7925\n",
      "Epoch 71/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4546 - acc: 0.8163 - val_loss: 0.4867 - val_acc: 0.7815\n",
      "Epoch 72/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4566 - acc: 0.8096 - val_loss: 0.4661 - val_acc: 0.8029\n",
      "Epoch 73/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4532 - acc: 0.8122 - val_loss: 0.4759 - val_acc: 0.7960\n",
      "Epoch 74/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4563 - acc: 0.8113 - val_loss: 0.4661 - val_acc: 0.8043\n",
      "Epoch 75/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.4505 - acc: 0.8168 - val_loss: 0.5001 - val_acc: 0.7898\n",
      "Epoch 76/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4561 - acc: 0.8111 - val_loss: 0.4777 - val_acc: 0.8001\n",
      "Epoch 77/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4476 - acc: 0.8165 - val_loss: 0.4616 - val_acc: 0.8029\n",
      "Epoch 78/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4517 - acc: 0.8170 - val_loss: 0.4643 - val_acc: 0.7967\n",
      "Epoch 79/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4496 - acc: 0.8132 - val_loss: 0.4649 - val_acc: 0.8050\n",
      "Epoch 80/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4479 - acc: 0.8189 - val_loss: 0.5050 - val_acc: 0.7870\n",
      "Epoch 81/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4487 - acc: 0.8091 - val_loss: 0.4581 - val_acc: 0.8043\n",
      "Epoch 82/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4516 - acc: 0.8168 - val_loss: 0.4630 - val_acc: 0.8022\n",
      "Epoch 83/500\n",
      "5782/5782 [==============================] - 0s 82us/step - loss: 0.4449 - acc: 0.8203 - val_loss: 0.4740 - val_acc: 0.7974\n",
      "Epoch 84/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.4487 - acc: 0.8182 - val_loss: 0.4655 - val_acc: 0.8022\n",
      "Epoch 85/500\n",
      "5782/5782 [==============================] - 0s 84us/step - loss: 0.4418 - acc: 0.8222 - val_loss: 0.4596 - val_acc: 0.8119\n",
      "Epoch 86/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4485 - acc: 0.8177 - val_loss: 0.4611 - val_acc: 0.8050\n",
      "Epoch 87/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4474 - acc: 0.8158 - val_loss: 0.4534 - val_acc: 0.8071\n",
      "Epoch 88/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4431 - acc: 0.8186 - val_loss: 0.4551 - val_acc: 0.8064\n",
      "Epoch 89/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4437 - acc: 0.8187 - val_loss: 0.4568 - val_acc: 0.8015\n",
      "Epoch 90/500\n",
      "5782/5782 [==============================] - 0s 61us/step - loss: 0.4479 - acc: 0.8148 - val_loss: 0.4831 - val_acc: 0.8036\n",
      "Epoch 91/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.4387 - acc: 0.8246 - val_loss: 0.4653 - val_acc: 0.8036\n",
      "Epoch 92/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4359 - acc: 0.8227 - val_loss: 0.4542 - val_acc: 0.8029\n",
      "Epoch 93/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4385 - acc: 0.8207 - val_loss: 0.4560 - val_acc: 0.8008\n",
      "Epoch 94/500\n",
      "5782/5782 [==============================] - 0s 82us/step - loss: 0.4393 - acc: 0.8198 - val_loss: 0.4618 - val_acc: 0.8167\n",
      "Epoch 95/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.4381 - acc: 0.8245 - val_loss: 0.4630 - val_acc: 0.8036\n",
      "Epoch 96/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4359 - acc: 0.8238 - val_loss: 0.4577 - val_acc: 0.8050\n",
      "Epoch 97/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4347 - acc: 0.8220 - val_loss: 0.4574 - val_acc: 0.8064\n",
      "Epoch 98/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4411 - acc: 0.8196 - val_loss: 0.4559 - val_acc: 0.8071\n",
      "Epoch 99/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4342 - acc: 0.8257 - val_loss: 0.4619 - val_acc: 0.8015\n",
      "Epoch 100/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.4355 - acc: 0.8231 - val_loss: 0.4530 - val_acc: 0.8126\n",
      "Epoch 101/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4321 - acc: 0.8305 - val_loss: 0.4673 - val_acc: 0.8098\n",
      "Epoch 102/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4321 - acc: 0.8231 - val_loss: 0.4608 - val_acc: 0.8029\n",
      "Epoch 103/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4457 - acc: 0.8205 - val_loss: 0.4486 - val_acc: 0.8091\n",
      "Epoch 104/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4280 - acc: 0.8286 - val_loss: 0.4424 - val_acc: 0.8154\n",
      "Epoch 105/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.4333 - acc: 0.8229 - val_loss: 0.4479 - val_acc: 0.8077\n",
      "Epoch 106/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.4330 - acc: 0.8260 - val_loss: 0.4491 - val_acc: 0.8105\n",
      "Epoch 107/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4337 - acc: 0.8217 - val_loss: 0.4459 - val_acc: 0.8105\n",
      "Epoch 108/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4301 - acc: 0.8265 - val_loss: 0.4500 - val_acc: 0.8043\n",
      "Epoch 109/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4321 - acc: 0.8220 - val_loss: 0.4800 - val_acc: 0.8043\n",
      "Epoch 110/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4384 - acc: 0.8274 - val_loss: 0.4434 - val_acc: 0.8160\n",
      "Epoch 111/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4315 - acc: 0.8270 - val_loss: 0.4411 - val_acc: 0.8119\n",
      "Epoch 112/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.4327 - acc: 0.8189 - val_loss: 0.4473 - val_acc: 0.8167\n",
      "Epoch 113/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4274 - acc: 0.8257 - val_loss: 0.4736 - val_acc: 0.7849\n",
      "Epoch 114/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.4396 - acc: 0.8143 - val_loss: 0.4835 - val_acc: 0.8057\n",
      "Epoch 115/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.4221 - acc: 0.8305 - val_loss: 0.4401 - val_acc: 0.8140\n",
      "Epoch 116/500\n",
      "5782/5782 [==============================] - 0s 83us/step - loss: 0.4279 - acc: 0.8283 - val_loss: 0.4435 - val_acc: 0.8077\n",
      "Epoch 117/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4224 - acc: 0.8300 - val_loss: 0.4434 - val_acc: 0.8209\n",
      "Epoch 118/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4215 - acc: 0.8290 - val_loss: 0.4445 - val_acc: 0.8084\n",
      "Epoch 119/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4300 - acc: 0.8303 - val_loss: 0.4407 - val_acc: 0.8126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4199 - acc: 0.8334 - val_loss: 0.4371 - val_acc: 0.8154\n",
      "Epoch 121/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4223 - acc: 0.8307 - val_loss: 0.4389 - val_acc: 0.8154\n",
      "Epoch 122/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.4275 - acc: 0.8269 - val_loss: 0.4588 - val_acc: 0.8105\n",
      "Epoch 123/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4268 - acc: 0.8272 - val_loss: 0.4386 - val_acc: 0.8140\n",
      "Epoch 124/500\n",
      "5782/5782 [==============================] - 0s 83us/step - loss: 0.4187 - acc: 0.8343 - val_loss: 0.4386 - val_acc: 0.8154\n",
      "Epoch 125/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4222 - acc: 0.8312 - val_loss: 0.4395 - val_acc: 0.8098\n",
      "Epoch 126/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4211 - acc: 0.8279 - val_loss: 0.4601 - val_acc: 0.8036\n",
      "Epoch 127/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4227 - acc: 0.8296 - val_loss: 0.4453 - val_acc: 0.8250\n",
      "Epoch 128/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.4189 - acc: 0.8331 - val_loss: 0.4502 - val_acc: 0.8015\n",
      "Epoch 129/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4251 - acc: 0.8248 - val_loss: 0.4472 - val_acc: 0.8112\n",
      "Epoch 130/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4179 - acc: 0.8315 - val_loss: 0.4319 - val_acc: 0.8278\n",
      "Epoch 131/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4206 - acc: 0.8312 - val_loss: 0.4470 - val_acc: 0.8029\n",
      "Epoch 132/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4195 - acc: 0.8322 - val_loss: 0.4341 - val_acc: 0.8167\n",
      "Epoch 133/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4167 - acc: 0.8355 - val_loss: 0.4418 - val_acc: 0.8223\n",
      "Epoch 134/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4177 - acc: 0.8315 - val_loss: 0.4450 - val_acc: 0.8133\n",
      "Epoch 135/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4126 - acc: 0.8393 - val_loss: 0.4440 - val_acc: 0.8223\n",
      "Epoch 136/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4201 - acc: 0.8277 - val_loss: 0.4300 - val_acc: 0.8271\n",
      "Epoch 137/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.4153 - acc: 0.8312 - val_loss: 0.4284 - val_acc: 0.8250\n",
      "Epoch 138/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4168 - acc: 0.8345 - val_loss: 0.4417 - val_acc: 0.8209\n",
      "Epoch 139/500\n",
      "5782/5782 [==============================] - 0s 81us/step - loss: 0.4226 - acc: 0.8310 - val_loss: 0.4326 - val_acc: 0.8202\n",
      "Epoch 140/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4194 - acc: 0.8281 - val_loss: 0.4762 - val_acc: 0.8050\n",
      "Epoch 141/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.4176 - acc: 0.8340 - val_loss: 0.4357 - val_acc: 0.8133\n",
      "Epoch 142/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4175 - acc: 0.8329 - val_loss: 0.4373 - val_acc: 0.8084\n",
      "Epoch 143/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4117 - acc: 0.8317 - val_loss: 0.4298 - val_acc: 0.8223\n",
      "Epoch 144/500\n",
      "5782/5782 [==============================] - 0s 85us/step - loss: 0.4174 - acc: 0.8341 - val_loss: 0.4367 - val_acc: 0.8105\n",
      "Epoch 145/500\n",
      "5782/5782 [==============================] - 0s 79us/step - loss: 0.4131 - acc: 0.8338 - val_loss: 0.4328 - val_acc: 0.8257\n",
      "Epoch 146/500\n",
      "5782/5782 [==============================] - 0s 82us/step - loss: 0.4158 - acc: 0.8367 - val_loss: 0.4393 - val_acc: 0.8112\n",
      "Epoch 147/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4138 - acc: 0.8360 - val_loss: 0.4304 - val_acc: 0.8174\n",
      "Epoch 148/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.4125 - acc: 0.8279 - val_loss: 0.4490 - val_acc: 0.8250\n",
      "Epoch 149/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.4161 - acc: 0.8338 - val_loss: 0.4386 - val_acc: 0.8250\n",
      "Epoch 150/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8371 - val_loss: 0.4307 - val_acc: 0.8195\n",
      "Epoch 151/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.4080 - acc: 0.8376 - val_loss: 0.4290 - val_acc: 0.8278\n",
      "Epoch 152/500\n",
      "5782/5782 [==============================] - 0s 56us/step - loss: 0.4098 - acc: 0.8357 - val_loss: 0.4307 - val_acc: 0.8188\n",
      "Epoch 153/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.4162 - acc: 0.8305 - val_loss: 0.4360 - val_acc: 0.8188\n",
      "Epoch 154/500\n",
      "5782/5782 [==============================] - 0s 52us/step - loss: 0.4101 - acc: 0.8352 - val_loss: 0.4391 - val_acc: 0.8250\n",
      "Epoch 155/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.4125 - acc: 0.8364 - val_loss: 0.4348 - val_acc: 0.8091\n",
      "Epoch 156/500\n",
      "5782/5782 [==============================] - 0s 53us/step - loss: 0.4112 - acc: 0.8376 - val_loss: 0.4573 - val_acc: 0.8174\n",
      "Epoch 157/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8367 - val_loss: 0.4274 - val_acc: 0.8160\n",
      "Epoch 158/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4111 - acc: 0.8373 - val_loss: 0.4302 - val_acc: 0.8216\n",
      "Epoch 159/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.4085 - acc: 0.8362 - val_loss: 0.4386 - val_acc: 0.8313\n",
      "Epoch 160/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.4085 - acc: 0.8354 - val_loss: 0.4316 - val_acc: 0.8278\n",
      "Epoch 161/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4098 - acc: 0.8371 - val_loss: 0.4476 - val_acc: 0.8237\n",
      "Epoch 162/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4122 - acc: 0.8343 - val_loss: 0.4771 - val_acc: 0.8015\n",
      "Epoch 163/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4212 - acc: 0.8326 - val_loss: 0.4474 - val_acc: 0.8202\n",
      "Epoch 164/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4053 - acc: 0.8367 - val_loss: 0.4254 - val_acc: 0.8202\n",
      "Epoch 165/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4023 - acc: 0.8395 - val_loss: 0.4260 - val_acc: 0.8340\n",
      "Epoch 166/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4081 - acc: 0.8392 - val_loss: 0.4293 - val_acc: 0.8154\n",
      "Epoch 167/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4066 - acc: 0.8373 - val_loss: 0.4200 - val_acc: 0.8306\n",
      "Epoch 168/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4046 - acc: 0.8411 - val_loss: 0.4272 - val_acc: 0.8409\n",
      "Epoch 169/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4051 - acc: 0.8421 - val_loss: 0.4292 - val_acc: 0.8313\n",
      "Epoch 170/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4167 - acc: 0.8307 - val_loss: 0.4295 - val_acc: 0.8320\n",
      "Epoch 171/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4006 - acc: 0.8395 - val_loss: 0.4354 - val_acc: 0.8077\n",
      "Epoch 172/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4050 - acc: 0.8392 - val_loss: 0.4410 - val_acc: 0.8285\n",
      "Epoch 173/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4034 - acc: 0.8397 - val_loss: 0.4446 - val_acc: 0.8202\n",
      "Epoch 174/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4030 - acc: 0.8392 - val_loss: 0.4303 - val_acc: 0.8271\n",
      "Epoch 175/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4048 - acc: 0.8407 - val_loss: 0.4247 - val_acc: 0.8237\n",
      "Epoch 176/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4017 - acc: 0.8376 - val_loss: 0.4242 - val_acc: 0.8326\n",
      "Epoch 177/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4062 - acc: 0.8373 - val_loss: 0.4473 - val_acc: 0.8278\n",
      "Epoch 178/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.4094 - acc: 0.8352 - val_loss: 0.4212 - val_acc: 0.8209\n",
      "Epoch 179/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3985 - acc: 0.8462 - val_loss: 0.4256 - val_acc: 0.8285\n",
      "Epoch 180/500\n",
      "5782/5782 [==============================] - 0s 59us/step - loss: 0.4016 - acc: 0.8423 - val_loss: 0.4178 - val_acc: 0.8402\n",
      "Epoch 181/500\n",
      "5782/5782 [==============================] - 0s 57us/step - loss: 0.3963 - acc: 0.8454 - val_loss: 0.4248 - val_acc: 0.8230\n",
      "Epoch 182/500\n",
      "5782/5782 [==============================] - 0s 60us/step - loss: 0.4002 - acc: 0.8412 - val_loss: 0.4263 - val_acc: 0.8188\n",
      "Epoch 183/500\n",
      "5782/5782 [==============================] - 0s 61us/step - loss: 0.4090 - acc: 0.8392 - val_loss: 0.4233 - val_acc: 0.8230\n",
      "Epoch 184/500\n",
      "5782/5782 [==============================] - 0s 61us/step - loss: 0.4037 - acc: 0.8416 - val_loss: 0.4279 - val_acc: 0.8202\n",
      "Epoch 185/500\n",
      "5782/5782 [==============================] - 0s 59us/step - loss: 0.4041 - acc: 0.8383 - val_loss: 0.4618 - val_acc: 0.8202\n",
      "Epoch 186/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4027 - acc: 0.8350 - val_loss: 0.4204 - val_acc: 0.8292\n",
      "Epoch 187/500\n",
      "5782/5782 [==============================] - 0s 62us/step - loss: 0.3989 - acc: 0.8386 - val_loss: 0.4227 - val_acc: 0.8326\n",
      "Epoch 188/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4001 - acc: 0.8426 - val_loss: 0.4217 - val_acc: 0.8292\n",
      "Epoch 189/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3979 - acc: 0.8409 - val_loss: 0.4230 - val_acc: 0.8333\n",
      "Epoch 190/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3984 - acc: 0.8405 - val_loss: 0.4256 - val_acc: 0.8264\n",
      "Epoch 191/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3994 - acc: 0.8428 - val_loss: 0.4228 - val_acc: 0.8375\n",
      "Epoch 192/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.4002 - acc: 0.8426 - val_loss: 0.4196 - val_acc: 0.8306\n",
      "Epoch 193/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.4013 - acc: 0.8381 - val_loss: 0.4260 - val_acc: 0.8306\n",
      "Epoch 194/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3983 - acc: 0.8428 - val_loss: 0.4237 - val_acc: 0.8264\n",
      "Epoch 195/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.4011 - acc: 0.8414 - val_loss: 0.4200 - val_acc: 0.8320\n",
      "Epoch 196/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3975 - acc: 0.8430 - val_loss: 0.4252 - val_acc: 0.8257\n",
      "Epoch 197/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.4014 - acc: 0.8416 - val_loss: 0.4308 - val_acc: 0.8223\n",
      "Epoch 198/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3937 - acc: 0.8423 - val_loss: 0.4406 - val_acc: 0.8091\n",
      "Epoch 199/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3976 - acc: 0.8412 - val_loss: 0.4246 - val_acc: 0.8278\n",
      "Epoch 200/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3940 - acc: 0.8419 - val_loss: 0.4215 - val_acc: 0.8195\n",
      "Epoch 201/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3916 - acc: 0.8461 - val_loss: 0.4223 - val_acc: 0.8320\n",
      "Epoch 202/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3933 - acc: 0.8461 - val_loss: 0.4224 - val_acc: 0.8243\n",
      "Epoch 203/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3964 - acc: 0.8405 - val_loss: 0.4592 - val_acc: 0.8237\n",
      "Epoch 204/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.4025 - acc: 0.8376 - val_loss: 0.4206 - val_acc: 0.8271\n",
      "Epoch 205/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3993 - acc: 0.8398 - val_loss: 0.4461 - val_acc: 0.8250\n",
      "Epoch 206/500\n",
      "5782/5782 [==============================] - 0s 62us/step - loss: 0.3924 - acc: 0.8456 - val_loss: 0.4122 - val_acc: 0.8444\n",
      "Epoch 207/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3942 - acc: 0.8457 - val_loss: 0.4631 - val_acc: 0.8209\n",
      "Epoch 208/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.4035 - acc: 0.8348 - val_loss: 0.4348 - val_acc: 0.8306\n",
      "Epoch 209/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3977 - acc: 0.8418 - val_loss: 0.4247 - val_acc: 0.8188\n",
      "Epoch 210/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3898 - acc: 0.8461 - val_loss: 0.4266 - val_acc: 0.8306\n",
      "Epoch 211/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3939 - acc: 0.8443 - val_loss: 0.4217 - val_acc: 0.8333\n",
      "Epoch 212/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.4088 - acc: 0.8326 - val_loss: 0.4880 - val_acc: 0.8043\n",
      "Epoch 213/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3933 - acc: 0.8481 - val_loss: 0.4149 - val_acc: 0.8361\n",
      "Epoch 214/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3912 - acc: 0.8480 - val_loss: 0.4185 - val_acc: 0.8292\n",
      "Epoch 215/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3873 - acc: 0.8502 - val_loss: 0.4223 - val_acc: 0.8223\n",
      "Epoch 216/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3959 - acc: 0.8426 - val_loss: 0.4236 - val_acc: 0.8299\n",
      "Epoch 217/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4011 - acc: 0.8379 - val_loss: 0.4294 - val_acc: 0.8326\n",
      "Epoch 218/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3901 - acc: 0.8449 - val_loss: 0.4180 - val_acc: 0.8368\n",
      "Epoch 219/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3934 - acc: 0.8421 - val_loss: 0.4185 - val_acc: 0.8368\n",
      "Epoch 220/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.4010 - acc: 0.8369 - val_loss: 0.4538 - val_acc: 0.8230\n",
      "Epoch 221/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.4057 - acc: 0.8398 - val_loss: 0.4336 - val_acc: 0.8306\n",
      "Epoch 222/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3994 - acc: 0.8423 - val_loss: 0.4198 - val_acc: 0.8389\n",
      "Epoch 223/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3963 - acc: 0.8442 - val_loss: 0.4571 - val_acc: 0.8209\n",
      "Epoch 224/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3934 - acc: 0.8447 - val_loss: 0.4195 - val_acc: 0.8237\n",
      "Epoch 225/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.3887 - acc: 0.8445 - val_loss: 0.4432 - val_acc: 0.8340\n",
      "Epoch 226/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3933 - acc: 0.8450 - val_loss: 0.4145 - val_acc: 0.8354\n",
      "Epoch 227/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3927 - acc: 0.8407 - val_loss: 0.4187 - val_acc: 0.8361\n",
      "Epoch 228/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3873 - acc: 0.8478 - val_loss: 0.4406 - val_acc: 0.8299\n",
      "Epoch 229/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3850 - acc: 0.8437 - val_loss: 0.4262 - val_acc: 0.8264\n",
      "Epoch 230/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3870 - acc: 0.8481 - val_loss: 0.4227 - val_acc: 0.8382\n",
      "Epoch 231/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3863 - acc: 0.8487 - val_loss: 0.4297 - val_acc: 0.8333\n",
      "Epoch 232/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.4002 - acc: 0.8438 - val_loss: 0.4186 - val_acc: 0.8299\n",
      "Epoch 233/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3858 - acc: 0.8521 - val_loss: 0.4161 - val_acc: 0.8292\n",
      "Epoch 234/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3889 - acc: 0.8456 - val_loss: 0.4194 - val_acc: 0.8216\n",
      "Epoch 235/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.3868 - acc: 0.8492 - val_loss: 0.4190 - val_acc: 0.8354\n",
      "Epoch 236/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3899 - acc: 0.8475 - val_loss: 0.4184 - val_acc: 0.8340\n",
      "Epoch 237/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3876 - acc: 0.8430 - val_loss: 0.4133 - val_acc: 0.8340\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5782/5782 [==============================] - 0s 61us/step - loss: 0.3872 - acc: 0.8452 - val_loss: 0.4202 - val_acc: 0.8402\n",
      "Epoch 239/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3832 - acc: 0.8499 - val_loss: 0.4164 - val_acc: 0.8285\n",
      "Epoch 240/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3868 - acc: 0.8495 - val_loss: 0.4143 - val_acc: 0.8306\n",
      "Epoch 241/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3806 - acc: 0.8535 - val_loss: 0.4408 - val_acc: 0.8292\n",
      "Epoch 242/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3887 - acc: 0.8487 - val_loss: 0.4145 - val_acc: 0.8416\n",
      "Epoch 243/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3864 - acc: 0.8509 - val_loss: 0.4247 - val_acc: 0.8333\n",
      "Epoch 244/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3894 - acc: 0.8513 - val_loss: 0.4131 - val_acc: 0.8271\n",
      "Epoch 245/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3882 - acc: 0.8454 - val_loss: 0.4116 - val_acc: 0.8430\n",
      "Epoch 246/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3862 - acc: 0.8478 - val_loss: 0.4211 - val_acc: 0.8216\n",
      "Epoch 247/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3945 - acc: 0.8430 - val_loss: 0.4400 - val_acc: 0.8071\n",
      "Epoch 248/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3897 - acc: 0.8464 - val_loss: 0.4342 - val_acc: 0.8202\n",
      "Epoch 249/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3847 - acc: 0.8494 - val_loss: 0.4204 - val_acc: 0.8250\n",
      "Epoch 250/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3865 - acc: 0.8499 - val_loss: 0.4304 - val_acc: 0.8340\n",
      "Epoch 251/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3792 - acc: 0.8535 - val_loss: 0.4273 - val_acc: 0.8285\n",
      "Epoch 252/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3845 - acc: 0.8481 - val_loss: 0.4135 - val_acc: 0.8354\n",
      "Epoch 253/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3859 - acc: 0.8464 - val_loss: 0.4163 - val_acc: 0.8306\n",
      "Epoch 254/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3862 - acc: 0.8481 - val_loss: 0.4322 - val_acc: 0.8140\n",
      "Epoch 255/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3876 - acc: 0.8475 - val_loss: 0.4148 - val_acc: 0.8396\n",
      "Epoch 256/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3918 - acc: 0.8433 - val_loss: 0.4213 - val_acc: 0.8237\n",
      "Epoch 257/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3844 - acc: 0.8521 - val_loss: 0.4360 - val_acc: 0.8375\n",
      "Epoch 258/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3868 - acc: 0.8525 - val_loss: 0.4138 - val_acc: 0.8389\n",
      "Epoch 259/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3812 - acc: 0.8558 - val_loss: 0.4285 - val_acc: 0.8347\n",
      "Epoch 260/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3783 - acc: 0.8545 - val_loss: 0.4160 - val_acc: 0.8347\n",
      "Epoch 261/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3797 - acc: 0.8511 - val_loss: 0.4185 - val_acc: 0.8271\n",
      "Epoch 262/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3895 - acc: 0.8480 - val_loss: 0.4310 - val_acc: 0.8389\n",
      "Epoch 263/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3795 - acc: 0.8494 - val_loss: 0.4290 - val_acc: 0.8285\n",
      "Epoch 264/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3817 - acc: 0.8501 - val_loss: 0.4169 - val_acc: 0.8257\n",
      "Epoch 265/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3880 - acc: 0.8428 - val_loss: 0.4114 - val_acc: 0.8320\n",
      "Epoch 266/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3783 - acc: 0.8584 - val_loss: 0.4067 - val_acc: 0.8472\n",
      "Epoch 267/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3781 - acc: 0.8544 - val_loss: 0.4202 - val_acc: 0.8278\n",
      "Epoch 268/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3878 - acc: 0.8513 - val_loss: 0.4135 - val_acc: 0.8382\n",
      "Epoch 269/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3830 - acc: 0.8530 - val_loss: 0.4179 - val_acc: 0.8333\n",
      "Epoch 270/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3840 - acc: 0.8544 - val_loss: 0.4114 - val_acc: 0.8382\n",
      "Epoch 271/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3823 - acc: 0.8495 - val_loss: 0.4075 - val_acc: 0.8451\n",
      "Epoch 272/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3773 - acc: 0.8492 - val_loss: 0.4257 - val_acc: 0.8375\n",
      "Epoch 273/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3792 - acc: 0.8513 - val_loss: 0.4234 - val_acc: 0.8347\n",
      "Epoch 274/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3816 - acc: 0.8488 - val_loss: 0.4277 - val_acc: 0.8195\n",
      "Epoch 275/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3876 - acc: 0.8462 - val_loss: 0.4393 - val_acc: 0.8354\n",
      "Epoch 276/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3865 - acc: 0.8449 - val_loss: 0.4129 - val_acc: 0.8402\n",
      "Epoch 277/500\n",
      "5782/5782 [==============================] - 1s 101us/step - loss: 0.3736 - acc: 0.8547 - val_loss: 0.4108 - val_acc: 0.8354\n",
      "Epoch 278/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3745 - acc: 0.8526 - val_loss: 0.4262 - val_acc: 0.8389\n",
      "Epoch 279/500\n",
      "5782/5782 [==============================] - 0s 79us/step - loss: 0.3760 - acc: 0.8558 - val_loss: 0.4094 - val_acc: 0.8458\n",
      "Epoch 280/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3800 - acc: 0.8521 - val_loss: 0.4266 - val_acc: 0.8278\n",
      "Epoch 281/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3770 - acc: 0.8499 - val_loss: 0.4102 - val_acc: 0.8396\n",
      "Epoch 282/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.3758 - acc: 0.8521 - val_loss: 0.4175 - val_acc: 0.8396\n",
      "Epoch 283/500\n",
      "5782/5782 [==============================] - 0s 81us/step - loss: 0.3813 - acc: 0.8520 - val_loss: 0.4187 - val_acc: 0.8320\n",
      "Epoch 284/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3824 - acc: 0.8499 - val_loss: 0.4127 - val_acc: 0.8416\n",
      "Epoch 285/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3780 - acc: 0.8497 - val_loss: 0.4166 - val_acc: 0.8292\n",
      "Epoch 286/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.3813 - acc: 0.8545 - val_loss: 0.4183 - val_acc: 0.8396\n",
      "Epoch 287/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3861 - acc: 0.8456 - val_loss: 0.4101 - val_acc: 0.8402\n",
      "Epoch 288/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.3867 - acc: 0.8445 - val_loss: 0.4361 - val_acc: 0.8306\n",
      "Epoch 289/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3812 - acc: 0.8476 - val_loss: 0.4079 - val_acc: 0.8458\n",
      "Epoch 290/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3796 - acc: 0.8511 - val_loss: 0.4125 - val_acc: 0.8271\n",
      "Epoch 291/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.3748 - acc: 0.8545 - val_loss: 0.4327 - val_acc: 0.8354\n",
      "Epoch 292/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3842 - acc: 0.8437 - val_loss: 0.4101 - val_acc: 0.8340\n",
      "Epoch 293/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3777 - acc: 0.8516 - val_loss: 0.4203 - val_acc: 0.8347\n",
      "Epoch 294/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3883 - acc: 0.8447 - val_loss: 0.4103 - val_acc: 0.8361\n",
      "Epoch 295/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3781 - acc: 0.8544 - val_loss: 0.4073 - val_acc: 0.8451\n",
      "Epoch 296/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3744 - acc: 0.8537 - val_loss: 0.4079 - val_acc: 0.8430\n",
      "Epoch 297/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3758 - acc: 0.8544 - val_loss: 0.4146 - val_acc: 0.8354\n",
      "Epoch 298/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3821 - acc: 0.8506 - val_loss: 0.4091 - val_acc: 0.8375\n",
      "Epoch 299/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3745 - acc: 0.8488 - val_loss: 0.4195 - val_acc: 0.8402\n",
      "Epoch 300/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3742 - acc: 0.8513 - val_loss: 0.4059 - val_acc: 0.8326\n",
      "Epoch 301/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3747 - acc: 0.8554 - val_loss: 0.4098 - val_acc: 0.8444\n",
      "Epoch 302/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3831 - acc: 0.8483 - val_loss: 0.4144 - val_acc: 0.8361\n",
      "Epoch 303/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.3744 - acc: 0.8516 - val_loss: 0.4235 - val_acc: 0.8230\n",
      "Epoch 304/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.3723 - acc: 0.8530 - val_loss: 0.4111 - val_acc: 0.8389\n",
      "Epoch 305/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.3865 - acc: 0.8469 - val_loss: 0.4128 - val_acc: 0.8416\n",
      "Epoch 306/500\n",
      "5782/5782 [==============================] - 0s 71us/step - loss: 0.3830 - acc: 0.8526 - val_loss: 0.4094 - val_acc: 0.8423\n",
      "Epoch 307/500\n",
      "5782/5782 [==============================] - 0s 76us/step - loss: 0.3753 - acc: 0.8545 - val_loss: 0.4115 - val_acc: 0.8361\n",
      "Epoch 308/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.3732 - acc: 0.8565 - val_loss: 0.4012 - val_acc: 0.8444\n",
      "Epoch 309/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3720 - acc: 0.8585 - val_loss: 0.4134 - val_acc: 0.8354\n",
      "Epoch 310/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3743 - acc: 0.8545 - val_loss: 0.4147 - val_acc: 0.8313\n",
      "Epoch 311/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3724 - acc: 0.8561 - val_loss: 0.4081 - val_acc: 0.8409\n",
      "Epoch 312/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3709 - acc: 0.8563 - val_loss: 0.4160 - val_acc: 0.8340\n",
      "Epoch 313/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3697 - acc: 0.8559 - val_loss: 0.4110 - val_acc: 0.8375\n",
      "Epoch 314/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3748 - acc: 0.8525 - val_loss: 0.4056 - val_acc: 0.8492\n",
      "Epoch 315/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3719 - acc: 0.8542 - val_loss: 0.4101 - val_acc: 0.8396\n",
      "Epoch 316/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3744 - acc: 0.8523 - val_loss: 0.4261 - val_acc: 0.8340\n",
      "Epoch 317/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3762 - acc: 0.8539 - val_loss: 0.4235 - val_acc: 0.8402\n",
      "Epoch 318/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3711 - acc: 0.8540 - val_loss: 0.4059 - val_acc: 0.8416\n",
      "Epoch 319/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3757 - acc: 0.8525 - val_loss: 0.4067 - val_acc: 0.8458\n",
      "Epoch 320/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3690 - acc: 0.8570 - val_loss: 0.4149 - val_acc: 0.8389\n",
      "Epoch 321/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3688 - acc: 0.8584 - val_loss: 0.4306 - val_acc: 0.8313\n",
      "Epoch 322/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3997 - acc: 0.8424 - val_loss: 0.4117 - val_acc: 0.8437\n",
      "Epoch 323/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3773 - acc: 0.8561 - val_loss: 0.4135 - val_acc: 0.8292\n",
      "Epoch 324/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3745 - acc: 0.8514 - val_loss: 0.4398 - val_acc: 0.8320\n",
      "Epoch 325/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3700 - acc: 0.8584 - val_loss: 0.4047 - val_acc: 0.8423\n",
      "Epoch 326/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.3759 - acc: 0.8504 - val_loss: 0.4254 - val_acc: 0.8375\n",
      "Epoch 327/500\n",
      "5782/5782 [==============================] - 0s 86us/step - loss: 0.3707 - acc: 0.8577 - val_loss: 0.4268 - val_acc: 0.8347\n",
      "Epoch 328/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3722 - acc: 0.8565 - val_loss: 0.4007 - val_acc: 0.8513\n",
      "Epoch 329/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3697 - acc: 0.8561 - val_loss: 0.4290 - val_acc: 0.8368\n",
      "Epoch 330/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.3741 - acc: 0.8509 - val_loss: 0.4131 - val_acc: 0.8437\n",
      "Epoch 331/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3684 - acc: 0.8578 - val_loss: 0.4117 - val_acc: 0.8389\n",
      "Epoch 332/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3731 - acc: 0.8584 - val_loss: 0.4059 - val_acc: 0.8396\n",
      "Epoch 333/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3717 - acc: 0.8554 - val_loss: 0.4106 - val_acc: 0.8361\n",
      "Epoch 334/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3693 - acc: 0.8568 - val_loss: 0.4175 - val_acc: 0.8375\n",
      "Epoch 335/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3741 - acc: 0.8563 - val_loss: 0.4057 - val_acc: 0.8451\n",
      "Epoch 336/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3718 - acc: 0.8526 - val_loss: 0.4078 - val_acc: 0.8347\n",
      "Epoch 337/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3662 - acc: 0.8559 - val_loss: 0.4058 - val_acc: 0.8423\n",
      "Epoch 338/500\n",
      "5782/5782 [==============================] - 0s 73us/step - loss: 0.3701 - acc: 0.8577 - val_loss: 0.4084 - val_acc: 0.8451\n",
      "Epoch 339/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3763 - acc: 0.8539 - val_loss: 0.4043 - val_acc: 0.8423\n",
      "Epoch 340/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.3749 - acc: 0.8525 - val_loss: 0.4109 - val_acc: 0.8333\n",
      "Epoch 341/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3698 - acc: 0.8590 - val_loss: 0.4164 - val_acc: 0.8416\n",
      "Epoch 342/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3681 - acc: 0.8585 - val_loss: 0.4050 - val_acc: 0.8444\n",
      "Epoch 343/500\n",
      "5782/5782 [==============================] - 0s 80us/step - loss: 0.3675 - acc: 0.8558 - val_loss: 0.4319 - val_acc: 0.8326\n",
      "Epoch 344/500\n",
      "5782/5782 [==============================] - 0s 70us/step - loss: 0.3636 - acc: 0.8587 - val_loss: 0.3991 - val_acc: 0.8520\n",
      "Epoch 345/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3646 - acc: 0.8580 - val_loss: 0.4112 - val_acc: 0.8444\n",
      "Epoch 346/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3707 - acc: 0.8559 - val_loss: 0.4062 - val_acc: 0.8444\n",
      "Epoch 347/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3630 - acc: 0.8604 - val_loss: 0.4068 - val_acc: 0.8416\n",
      "Epoch 348/500\n",
      "5782/5782 [==============================] - 0s 74us/step - loss: 0.3704 - acc: 0.8520 - val_loss: 0.4091 - val_acc: 0.8527\n",
      "Epoch 349/500\n",
      "5782/5782 [==============================] - 0s 78us/step - loss: 0.3729 - acc: 0.8545 - val_loss: 0.4105 - val_acc: 0.8368\n",
      "Epoch 350/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3698 - acc: 0.8622 - val_loss: 0.4087 - val_acc: 0.8430\n",
      "Epoch 351/500\n",
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3635 - acc: 0.8585 - val_loss: 0.4003 - val_acc: 0.8444\n",
      "Epoch 352/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3694 - acc: 0.8556 - val_loss: 0.4093 - val_acc: 0.8340\n",
      "Epoch 353/500\n",
      "5782/5782 [==============================] - 0s 75us/step - loss: 0.3773 - acc: 0.8570 - val_loss: 0.4099 - val_acc: 0.8402\n",
      "Epoch 354/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3664 - acc: 0.8599 - val_loss: 0.4278 - val_acc: 0.8375\n",
      "Epoch 355/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3658 - acc: 0.8594 - val_loss: 0.4191 - val_acc: 0.8333\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5782/5782 [==============================] - 0s 68us/step - loss: 0.3660 - acc: 0.8592 - val_loss: 0.4109 - val_acc: 0.8361\n",
      "Epoch 357/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.3689 - acc: 0.8533 - val_loss: 0.4007 - val_acc: 0.8472\n",
      "Epoch 358/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3670 - acc: 0.8597 - val_loss: 0.4046 - val_acc: 0.8458\n",
      "Epoch 359/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3682 - acc: 0.8566 - val_loss: 0.4168 - val_acc: 0.8326\n",
      "Epoch 360/500\n",
      "5782/5782 [==============================] - 0s 63us/step - loss: 0.3712 - acc: 0.8570 - val_loss: 0.4052 - val_acc: 0.8423\n",
      "Epoch 361/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3654 - acc: 0.8565 - val_loss: 0.4014 - val_acc: 0.8472\n",
      "Epoch 362/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3702 - acc: 0.8558 - val_loss: 0.4089 - val_acc: 0.8389\n",
      "Epoch 363/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3698 - acc: 0.8577 - val_loss: 0.4009 - val_acc: 0.8437\n",
      "Epoch 364/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3622 - acc: 0.8603 - val_loss: 0.4091 - val_acc: 0.8492\n",
      "Epoch 365/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3685 - acc: 0.8597 - val_loss: 0.3990 - val_acc: 0.8492\n",
      "Epoch 366/500\n",
      "5782/5782 [==============================] - 0s 86us/step - loss: 0.3639 - acc: 0.8622 - val_loss: 0.4089 - val_acc: 0.8465\n",
      "Epoch 367/500\n",
      "5782/5782 [==============================] - 0s 82us/step - loss: 0.3662 - acc: 0.8585 - val_loss: 0.4174 - val_acc: 0.8375\n",
      "Epoch 368/500\n",
      "5782/5782 [==============================] - 0s 85us/step - loss: 0.3667 - acc: 0.8592 - val_loss: 0.4128 - val_acc: 0.8416\n",
      "Epoch 369/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3635 - acc: 0.8582 - val_loss: 0.4065 - val_acc: 0.8354\n",
      "Epoch 370/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3635 - acc: 0.8580 - val_loss: 0.4059 - val_acc: 0.8485\n",
      "Epoch 371/500\n",
      "5782/5782 [==============================] - 0s 72us/step - loss: 0.3638 - acc: 0.8580 - val_loss: 0.4104 - val_acc: 0.8451\n",
      "Epoch 372/500\n",
      "5782/5782 [==============================] - 0s 57us/step - loss: 0.3678 - acc: 0.8578 - val_loss: 0.4071 - val_acc: 0.8485\n",
      "Epoch 373/500\n",
      "5782/5782 [==============================] - 0s 85us/step - loss: 0.3646 - acc: 0.8585 - val_loss: 0.4056 - val_acc: 0.8499\n",
      "Epoch 374/500\n",
      "5782/5782 [==============================] - 0s 55us/step - loss: 0.3662 - acc: 0.8570 - val_loss: 0.4058 - val_acc: 0.8479\n",
      "Epoch 375/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3648 - acc: 0.8609 - val_loss: 0.4000 - val_acc: 0.8451\n",
      "Epoch 376/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3689 - acc: 0.8580 - val_loss: 0.3969 - val_acc: 0.8520\n",
      "Epoch 377/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3703 - acc: 0.8544 - val_loss: 0.4258 - val_acc: 0.8292\n",
      "Epoch 378/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3650 - acc: 0.8608 - val_loss: 0.4037 - val_acc: 0.8527\n",
      "Epoch 379/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3618 - acc: 0.8609 - val_loss: 0.4135 - val_acc: 0.8409\n",
      "Epoch 380/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3654 - acc: 0.8599 - val_loss: 0.4020 - val_acc: 0.8492\n",
      "Epoch 381/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3663 - acc: 0.8575 - val_loss: 0.3940 - val_acc: 0.8527\n",
      "Epoch 382/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3599 - acc: 0.8648 - val_loss: 0.4025 - val_acc: 0.8479\n",
      "Epoch 383/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3589 - acc: 0.8622 - val_loss: 0.4254 - val_acc: 0.8382\n",
      "Epoch 384/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3652 - acc: 0.8599 - val_loss: 0.3988 - val_acc: 0.8513\n",
      "Epoch 385/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3668 - acc: 0.8590 - val_loss: 0.4140 - val_acc: 0.8472\n",
      "Epoch 386/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3655 - acc: 0.8616 - val_loss: 0.3987 - val_acc: 0.8472\n",
      "Epoch 387/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3630 - acc: 0.8596 - val_loss: 0.4015 - val_acc: 0.8437\n",
      "Epoch 388/500\n",
      "5782/5782 [==============================] - 0s 79us/step - loss: 0.3664 - acc: 0.8559 - val_loss: 0.4250 - val_acc: 0.8402\n",
      "Epoch 389/500\n",
      "5782/5782 [==============================] - 0s 67us/step - loss: 0.3664 - acc: 0.8604 - val_loss: 0.4054 - val_acc: 0.8499\n",
      "Epoch 390/500\n",
      "5782/5782 [==============================] - 0s 50us/step - loss: 0.3582 - acc: 0.8620 - val_loss: 0.4001 - val_acc: 0.8479\n",
      "Epoch 391/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3637 - acc: 0.8575 - val_loss: 0.4392 - val_acc: 0.8326\n",
      "Epoch 392/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3673 - acc: 0.8590 - val_loss: 0.3972 - val_acc: 0.8472\n",
      "Epoch 393/500\n",
      "5782/5782 [==============================] - 0s 50us/step - loss: 0.3600 - acc: 0.8618 - val_loss: 0.4075 - val_acc: 0.8416\n",
      "Epoch 394/500\n",
      "5782/5782 [==============================] - 0s 53us/step - loss: 0.3706 - acc: 0.8540 - val_loss: 0.4006 - val_acc: 0.8513\n",
      "Epoch 395/500\n",
      "5782/5782 [==============================] - 0s 50us/step - loss: 0.3627 - acc: 0.8566 - val_loss: 0.3990 - val_acc: 0.8451\n",
      "Epoch 396/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3632 - acc: 0.8609 - val_loss: 0.4010 - val_acc: 0.8479\n",
      "Epoch 397/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3612 - acc: 0.8608 - val_loss: 0.3959 - val_acc: 0.8520\n",
      "Epoch 398/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3649 - acc: 0.8599 - val_loss: 0.4154 - val_acc: 0.8368\n",
      "Epoch 399/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3639 - acc: 0.8573 - val_loss: 0.4154 - val_acc: 0.8423\n",
      "Epoch 400/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3657 - acc: 0.8563 - val_loss: 0.4016 - val_acc: 0.8492\n",
      "Epoch 401/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3622 - acc: 0.8563 - val_loss: 0.3972 - val_acc: 0.8492\n",
      "Epoch 402/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3634 - acc: 0.8604 - val_loss: 0.3965 - val_acc: 0.8485\n",
      "Epoch 403/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3722 - acc: 0.8596 - val_loss: 0.4171 - val_acc: 0.8430\n",
      "Epoch 404/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3644 - acc: 0.8627 - val_loss: 0.4138 - val_acc: 0.8396\n",
      "Epoch 405/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3592 - acc: 0.8644 - val_loss: 0.3997 - val_acc: 0.8402\n",
      "Epoch 406/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3664 - acc: 0.8535 - val_loss: 0.4064 - val_acc: 0.8451\n",
      "Epoch 407/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3529 - acc: 0.8649 - val_loss: 0.4026 - val_acc: 0.8513\n",
      "Epoch 408/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3573 - acc: 0.8675 - val_loss: 0.3974 - val_acc: 0.8499\n",
      "Epoch 409/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3679 - acc: 0.8573 - val_loss: 0.4015 - val_acc: 0.8402\n",
      "Epoch 410/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.3654 - acc: 0.8568 - val_loss: 0.4107 - val_acc: 0.8437\n",
      "Epoch 411/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3633 - acc: 0.8570 - val_loss: 0.3975 - val_acc: 0.8492\n",
      "Epoch 412/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3591 - acc: 0.8627 - val_loss: 0.4007 - val_acc: 0.8513\n",
      "Epoch 413/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3623 - acc: 0.8596 - val_loss: 0.4058 - val_acc: 0.8472\n",
      "Epoch 414/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3642 - acc: 0.8604 - val_loss: 0.4162 - val_acc: 0.8361\n",
      "Epoch 415/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3694 - acc: 0.8551 - val_loss: 0.4031 - val_acc: 0.8451\n",
      "Epoch 416/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3639 - acc: 0.8580 - val_loss: 0.4133 - val_acc: 0.8437\n",
      "Epoch 417/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3552 - acc: 0.8646 - val_loss: 0.4042 - val_acc: 0.8458\n",
      "Epoch 418/500\n",
      "5782/5782 [==============================] - 0s 50us/step - loss: 0.3556 - acc: 0.8630 - val_loss: 0.4015 - val_acc: 0.8451\n",
      "Epoch 419/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3591 - acc: 0.8594 - val_loss: 0.3929 - val_acc: 0.8582\n",
      "Epoch 420/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3602 - acc: 0.8641 - val_loss: 0.4331 - val_acc: 0.8313\n",
      "Epoch 421/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3577 - acc: 0.8613 - val_loss: 0.3977 - val_acc: 0.8492\n",
      "Epoch 422/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3638 - acc: 0.8571 - val_loss: 0.3956 - val_acc: 0.8430\n",
      "Epoch 423/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3569 - acc: 0.8660 - val_loss: 0.4002 - val_acc: 0.8492\n",
      "Epoch 424/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3588 - acc: 0.8649 - val_loss: 0.3977 - val_acc: 0.8485\n",
      "Epoch 425/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3661 - acc: 0.8608 - val_loss: 0.4069 - val_acc: 0.8472\n",
      "Epoch 426/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3639 - acc: 0.8589 - val_loss: 0.4008 - val_acc: 0.8451\n",
      "Epoch 427/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.3553 - acc: 0.8630 - val_loss: 0.4125 - val_acc: 0.8423\n",
      "Epoch 428/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3582 - acc: 0.8651 - val_loss: 0.4203 - val_acc: 0.8375\n",
      "Epoch 429/500\n",
      "5782/5782 [==============================] - 0s 50us/step - loss: 0.3584 - acc: 0.8589 - val_loss: 0.3958 - val_acc: 0.8485\n",
      "Epoch 430/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3572 - acc: 0.8587 - val_loss: 0.4092 - val_acc: 0.8458\n",
      "Epoch 431/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3556 - acc: 0.8630 - val_loss: 0.4043 - val_acc: 0.8472\n",
      "Epoch 432/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3625 - acc: 0.8589 - val_loss: 0.4285 - val_acc: 0.8368\n",
      "Epoch 433/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3653 - acc: 0.8599 - val_loss: 0.3945 - val_acc: 0.8506\n",
      "Epoch 434/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3659 - acc: 0.8620 - val_loss: 0.4027 - val_acc: 0.8458\n",
      "Epoch 435/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.3547 - acc: 0.8660 - val_loss: 0.4092 - val_acc: 0.8472\n",
      "Epoch 436/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3539 - acc: 0.8608 - val_loss: 0.4162 - val_acc: 0.8354\n",
      "Epoch 437/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3632 - acc: 0.8615 - val_loss: 0.3975 - val_acc: 0.8520\n",
      "Epoch 438/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3593 - acc: 0.8634 - val_loss: 0.4090 - val_acc: 0.8472\n",
      "Epoch 439/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3584 - acc: 0.8639 - val_loss: 0.4602 - val_acc: 0.8264\n",
      "Epoch 440/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3634 - acc: 0.8570 - val_loss: 0.4175 - val_acc: 0.8409\n",
      "Epoch 441/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3608 - acc: 0.8609 - val_loss: 0.4102 - val_acc: 0.8451\n",
      "Epoch 442/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3572 - acc: 0.8587 - val_loss: 0.4145 - val_acc: 0.8472\n",
      "Epoch 443/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.3564 - acc: 0.8642 - val_loss: 0.4041 - val_acc: 0.8520\n",
      "Epoch 444/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3519 - acc: 0.8667 - val_loss: 0.3998 - val_acc: 0.8555\n",
      "Epoch 445/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3611 - acc: 0.8616 - val_loss: 0.4009 - val_acc: 0.8499\n",
      "Epoch 446/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3537 - acc: 0.8653 - val_loss: 0.4214 - val_acc: 0.8389\n",
      "Epoch 447/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3579 - acc: 0.8635 - val_loss: 0.4041 - val_acc: 0.8430\n",
      "Epoch 448/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3537 - acc: 0.8653 - val_loss: 0.3925 - val_acc: 0.8548\n",
      "Epoch 449/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3513 - acc: 0.8648 - val_loss: 0.4015 - val_acc: 0.8499\n",
      "Epoch 450/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3522 - acc: 0.8667 - val_loss: 0.4177 - val_acc: 0.8299\n",
      "Epoch 451/500\n",
      "5782/5782 [==============================] - 0s 49us/step - loss: 0.3606 - acc: 0.8627 - val_loss: 0.3931 - val_acc: 0.8541\n",
      "Epoch 452/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3554 - acc: 0.8635 - val_loss: 0.4038 - val_acc: 0.8506\n",
      "Epoch 453/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3613 - acc: 0.8658 - val_loss: 0.4100 - val_acc: 0.8451\n",
      "Epoch 454/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3587 - acc: 0.8623 - val_loss: 0.3967 - val_acc: 0.8465\n",
      "Epoch 455/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3553 - acc: 0.8649 - val_loss: 0.3965 - val_acc: 0.8520\n",
      "Epoch 456/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3521 - acc: 0.8649 - val_loss: 0.4187 - val_acc: 0.8299\n",
      "Epoch 457/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3633 - acc: 0.8575 - val_loss: 0.3991 - val_acc: 0.8492\n",
      "Epoch 458/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3481 - acc: 0.8670 - val_loss: 0.3967 - val_acc: 0.8520\n",
      "Epoch 459/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3580 - acc: 0.8635 - val_loss: 0.3941 - val_acc: 0.8534\n",
      "Epoch 460/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3559 - acc: 0.8608 - val_loss: 0.4217 - val_acc: 0.8306\n",
      "Epoch 461/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3605 - acc: 0.8590 - val_loss: 0.4075 - val_acc: 0.8354\n",
      "Epoch 462/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3663 - acc: 0.8608 - val_loss: 0.4077 - val_acc: 0.8416\n",
      "Epoch 463/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3624 - acc: 0.8603 - val_loss: 0.4177 - val_acc: 0.8458\n",
      "Epoch 464/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3605 - acc: 0.8585 - val_loss: 0.3946 - val_acc: 0.8568\n",
      "Epoch 465/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3740 - acc: 0.8568 - val_loss: 0.4077 - val_acc: 0.8444\n",
      "Epoch 466/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3528 - acc: 0.8684 - val_loss: 0.3966 - val_acc: 0.8555\n",
      "Epoch 467/500\n",
      "5782/5782 [==============================] - 0s 47us/step - loss: 0.3594 - acc: 0.8604 - val_loss: 0.4029 - val_acc: 0.8541\n",
      "Epoch 468/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3540 - acc: 0.8627 - val_loss: 0.3984 - val_acc: 0.8520\n",
      "Epoch 469/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3531 - acc: 0.8675 - val_loss: 0.4337 - val_acc: 0.8340\n",
      "Epoch 470/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3574 - acc: 0.8590 - val_loss: 0.3942 - val_acc: 0.8513\n",
      "Epoch 471/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3509 - acc: 0.8661 - val_loss: 0.3964 - val_acc: 0.8513\n",
      "Epoch 472/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3531 - acc: 0.8625 - val_loss: 0.3984 - val_acc: 0.8513\n",
      "Epoch 473/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3546 - acc: 0.8675 - val_loss: 0.3980 - val_acc: 0.8506\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3533 - acc: 0.8670 - val_loss: 0.4128 - val_acc: 0.8423\n",
      "Epoch 475/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3556 - acc: 0.8620 - val_loss: 0.3976 - val_acc: 0.8506\n",
      "Epoch 476/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3573 - acc: 0.8609 - val_loss: 0.4045 - val_acc: 0.8437\n",
      "Epoch 477/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3572 - acc: 0.8615 - val_loss: 0.3926 - val_acc: 0.8555\n",
      "Epoch 478/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3527 - acc: 0.8684 - val_loss: 0.3898 - val_acc: 0.8555\n",
      "Epoch 479/500\n",
      "5782/5782 [==============================] - 0s 44us/step - loss: 0.3480 - acc: 0.8687 - val_loss: 0.4013 - val_acc: 0.8499\n",
      "Epoch 480/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3614 - acc: 0.8658 - val_loss: 0.3983 - val_acc: 0.8492\n",
      "Epoch 481/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3503 - acc: 0.8691 - val_loss: 0.4083 - val_acc: 0.8479\n",
      "Epoch 482/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3456 - acc: 0.8661 - val_loss: 0.3945 - val_acc: 0.8506\n",
      "Epoch 483/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3568 - acc: 0.8677 - val_loss: 0.4079 - val_acc: 0.8479\n",
      "Epoch 484/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3520 - acc: 0.8615 - val_loss: 0.3972 - val_acc: 0.8534\n",
      "Epoch 485/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3512 - acc: 0.8686 - val_loss: 0.4116 - val_acc: 0.8430\n",
      "Epoch 486/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3550 - acc: 0.8673 - val_loss: 0.4070 - val_acc: 0.8458\n",
      "Epoch 487/500\n",
      "5782/5782 [==============================] - 0s 53us/step - loss: 0.3442 - acc: 0.8692 - val_loss: 0.3877 - val_acc: 0.8568\n",
      "Epoch 488/500\n",
      "5782/5782 [==============================] - 0s 64us/step - loss: 0.3574 - acc: 0.8577 - val_loss: 0.3921 - val_acc: 0.8541\n",
      "Epoch 489/500\n",
      "5782/5782 [==============================] - 0s 77us/step - loss: 0.3494 - acc: 0.8672 - val_loss: 0.3931 - val_acc: 0.8527\n",
      "Epoch 490/500\n",
      "5782/5782 [==============================] - 0s 79us/step - loss: 0.3492 - acc: 0.8663 - val_loss: 0.4092 - val_acc: 0.8485\n",
      "Epoch 491/500\n",
      "5782/5782 [==============================] - 1s 87us/step - loss: 0.3544 - acc: 0.8667 - val_loss: 0.4125 - val_acc: 0.8354\n",
      "Epoch 492/500\n",
      "5782/5782 [==============================] - 0s 65us/step - loss: 0.3568 - acc: 0.8615 - val_loss: 0.4006 - val_acc: 0.8589\n",
      "Epoch 493/500\n",
      "5782/5782 [==============================] - 0s 69us/step - loss: 0.3642 - acc: 0.8639 - val_loss: 0.4029 - val_acc: 0.8575\n",
      "Epoch 494/500\n",
      "5782/5782 [==============================] - 0s 48us/step - loss: 0.3517 - acc: 0.8701 - val_loss: 0.4013 - val_acc: 0.8499\n",
      "Epoch 495/500\n",
      "5782/5782 [==============================] - 0s 46us/step - loss: 0.3478 - acc: 0.8691 - val_loss: 0.4011 - val_acc: 0.8451\n",
      "Epoch 496/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3516 - acc: 0.8648 - val_loss: 0.4011 - val_acc: 0.8499\n",
      "Epoch 497/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3541 - acc: 0.8618 - val_loss: 0.3925 - val_acc: 0.8582\n",
      "Epoch 498/500\n",
      "5782/5782 [==============================] - 0s 66us/step - loss: 0.3506 - acc: 0.8654 - val_loss: 0.4025 - val_acc: 0.8527\n",
      "Epoch 499/500\n",
      "5782/5782 [==============================] - 0s 56us/step - loss: 0.3528 - acc: 0.8649 - val_loss: 0.4060 - val_acc: 0.8451\n",
      "Epoch 500/500\n",
      "5782/5782 [==============================] - 0s 45us/step - loss: 0.3693 - acc: 0.8549 - val_loss: 0.4036 - val_acc: 0.8520\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "ANN_history = model_NN.fit(X_train_scaled, Y_train,batch_size=128,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = ANN_history.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(ANN_history.history['acc'], '-o', label='train')\n",
    "plt.plot(ANN_history.history['val_acc'], '-*', label='val')\n",
    "\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Accuracy score vs. Epochs\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3099/3099 [==============================] - 0s 40us/step\n",
      "Test loss: 0.3875258122097488\n",
      "Test ACC: 0.8531784449096033\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model_NN.evaluate(X_test_scaled, Y_test, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test ACC:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_NN_prob = model_NN.predict(pre_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df_NN= (y_pre_df_NN_prob>0.5).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bots detection compile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pre_df_scaled.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_detection_df = pd.DataFrame(np.column_stack([y_pre_df_logreg, y_pre_df_PolyL,y_pre_df_lda,y_pre_df_qda,y_pre_df_rf,y_pre_df_adaboost,y_pre_df_xgboost,y_pre_df_KNN,y_pre_df_svm, y_pre_df_NN,y_pre_df_NN_prob ]), \n",
    "                               columns=['Linear LR', 'Polynomial LR', 'LDA', 'QDA','Random Forest',  'AdaBoost', 'XGBoost', 'KNN', 'SVM','ANN','ANN_prob'],\n",
    "                               index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear LR</th>\n",
       "      <th>Polynomial LR</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>ANN</th>\n",
       "      <th>ANN_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876476261220179968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.602416e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909863671563739136</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.193622e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951973545831223296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.267130e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981943174947065856</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.538849e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735793156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.535614e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698968509091614720</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.515137e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040722169574187010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019044289278443520</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680649e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821278120518946816</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.710731e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003128394836578305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.990919e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977627209757323271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.361537e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749416405846548482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.886560e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890290830082277379</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.245556e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016367299882778626</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.230076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577652745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.413292e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008111981822468102</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.999403e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946543746</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.713931e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730545050388594690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.399338e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189756939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.106733e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766167322109284352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770908e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24018964</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916163e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815281892345991180</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.151847e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388173846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.038922e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293290007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234255e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200576020</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.111508e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49324055</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.037926e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560326682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.136971e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556955675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.407551e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310028318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.042047e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249739297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589251639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.420114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512416822</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.813938e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167639097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.876086e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887623959688171520</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.737588e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706133453339807744</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.410450e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956912991244570624</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.953828e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999687825497968640</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.205622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848232140332519424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.577145e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39564929</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.325929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881319251453333504</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.131989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231658049</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.232862e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030089505460637696</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.998093e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18691648</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.056782e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817825777932607489</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.872624e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21915395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.328680e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355739210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.191036e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150931027</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.524966e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011246062315687937</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.981698e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900437891373047809</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.604716e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32523862</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.551734e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40040033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.698041e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89265769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.927092e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770095723</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.508959e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21786220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.653877e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044666765790334978</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559955566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.705810e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870274473391398912</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.247090e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930214719062908928</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.829270e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594030193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.065634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850161357295112194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.807972e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Linear LR  Polynomial LR  LDA  QDA  Random Forest  \\\n",
       "User ID                                                                  \n",
       "876476261220179968         0.0            0.0  0.0  0.0            0.0   \n",
       "909863671563739136         1.0            0.0  1.0  1.0            0.0   \n",
       "951973545831223296         1.0            0.0  1.0  1.0            0.0   \n",
       "981943174947065856         1.0            1.0  1.0  0.0            0.0   \n",
       "4735793156                 0.0            0.0  0.0  0.0            0.0   \n",
       "698968509091614720         1.0            1.0  1.0  1.0            0.0   \n",
       "1040722169574187010        1.0            1.0  1.0  1.0            0.0   \n",
       "1019044289278443520        1.0            1.0  1.0  1.0            0.0   \n",
       "821278120518946816         1.0            1.0  1.0  0.0            0.0   \n",
       "1003128394836578305        1.0            1.0  1.0  1.0            0.0   \n",
       "977627209757323271         1.0            1.0  1.0  0.0            0.0   \n",
       "749416405846548482         0.0            0.0  1.0  0.0            0.0   \n",
       "890290830082277379         1.0            0.0  0.0  1.0            0.0   \n",
       "1016367299882778626        1.0            1.0  1.0  1.0            0.0   \n",
       "577652745                  0.0            0.0  1.0  1.0            0.0   \n",
       "1008111981822468102        1.0            1.0  1.0  1.0            0.0   \n",
       "2946543746                 0.0            0.0  0.0  0.0            0.0   \n",
       "730545050388594690         1.0            1.0  0.0  1.0            0.0   \n",
       "1189756939                 0.0            0.0  1.0  0.0            0.0   \n",
       "766167322109284352         1.0            0.0  1.0  1.0            0.0   \n",
       "24018964                   0.0            0.0  0.0  0.0            0.0   \n",
       "815281892345991180         1.0            0.0  1.0  0.0            0.0   \n",
       "388173846                  0.0            0.0  0.0  0.0            0.0   \n",
       "293290007                  1.0            1.0  1.0  1.0            1.0   \n",
       "2200576020                 1.0            0.0  1.0  1.0            0.0   \n",
       "49324055                   1.0            0.0  1.0  1.0            0.0   \n",
       "560326682                  0.0            0.0  0.0  0.0            0.0   \n",
       "556955675                  0.0            0.0  0.0  0.0            0.0   \n",
       "310028318                  0.0            0.0  0.0  0.0            0.0   \n",
       "249739297                  0.0            0.0  0.0  0.0            0.0   \n",
       "...                        ...            ...  ...  ...            ...   \n",
       "1589251639                 0.0            0.0  0.0  0.0            0.0   \n",
       "1512416822                 1.0            0.0  1.0  1.0            0.0   \n",
       "3167639097                 0.0            0.0  0.0  0.0            0.0   \n",
       "887623959688171520         1.0            0.0  1.0  1.0            0.0   \n",
       "706133453339807744         0.0            0.0  0.0  0.0            0.0   \n",
       "956912991244570624         1.0            1.0  1.0  1.0            0.0   \n",
       "999687825497968640         1.0            1.0  1.0  1.0            0.0   \n",
       "848232140332519424         0.0            0.0  0.0  0.0            1.0   \n",
       "39564929                   0.0            0.0  0.0  0.0            0.0   \n",
       "881319251453333504         1.0            1.0  1.0  1.0            0.0   \n",
       "2231658049                 1.0            0.0  1.0  0.0            0.0   \n",
       "1030089505460637696        1.0            1.0  1.0  1.0            0.0   \n",
       "18691648                   1.0            1.0  1.0  1.0            0.0   \n",
       "817825777932607489         1.0            0.0  1.0  0.0            0.0   \n",
       "21915395                   0.0            0.0  0.0  0.0            0.0   \n",
       "355739210                  0.0            0.0  0.0  0.0            0.0   \n",
       "150931027                  0.0            0.0  0.0  0.0            0.0   \n",
       "1011246062315687937        1.0            1.0  1.0  1.0            0.0   \n",
       "900437891373047809         1.0            1.0  1.0  1.0            0.0   \n",
       "32523862                   0.0            0.0  0.0  0.0            0.0   \n",
       "40040033                   0.0            0.0  0.0  1.0            0.0   \n",
       "89265769                   0.0            0.0  0.0  0.0            0.0   \n",
       "2770095723                 1.0            0.0  1.0  1.0            0.0   \n",
       "21786220                   0.0            0.0  0.0  0.0            1.0   \n",
       "1044666765790334978        1.0            1.0  1.0  1.0            0.0   \n",
       "559955566                  0.0            0.0  0.0  0.0            0.0   \n",
       "870274473391398912         0.0            0.0  0.0  0.0            0.0   \n",
       "930214719062908928         1.0            1.0  1.0  1.0            0.0   \n",
       "594030193                  0.0            0.0  0.0  0.0            0.0   \n",
       "850161357295112194         1.0            0.0  0.0  0.0            0.0   \n",
       "\n",
       "                     AdaBoost  XGBoost  KNN  SVM  ANN      ANN_prob  \n",
       "User ID                                                              \n",
       "876476261220179968        0.0      0.0  0.0  0.0  0.0  2.602416e-02  \n",
       "909863671563739136        0.0      0.0  0.0  1.0  0.0  7.193622e-02  \n",
       "951973545831223296        0.0      0.0  1.0  1.0  0.0  3.267130e-02  \n",
       "981943174947065856        0.0      0.0  0.0  0.0  0.0  6.538849e-02  \n",
       "4735793156                0.0      0.0  0.0  0.0  0.0  3.535614e-03  \n",
       "698968509091614720        0.0      0.0  0.0  1.0  0.0  4.515137e-02  \n",
       "1040722169574187010       0.0      0.0  1.0  0.0  1.0  1.000000e+00  \n",
       "1019044289278443520       0.0      0.0  0.0  0.0  0.0  3.680649e-02  \n",
       "821278120518946816        0.0      0.0  0.0  1.0  0.0  1.710731e-01  \n",
       "1003128394836578305       0.0      0.0  0.0  0.0  0.0  6.990919e-04  \n",
       "977627209757323271        0.0      0.0  1.0  1.0  0.0  6.361537e-02  \n",
       "749416405846548482        0.0      0.0  0.0  1.0  0.0  4.886560e-02  \n",
       "890290830082277379        0.0      0.0  0.0  0.0  0.0  1.245556e-06  \n",
       "1016367299882778626       0.0      0.0  0.0  0.0  0.0  1.230076e-01  \n",
       "577652745                 0.0      0.0  1.0  1.0  0.0  2.413292e-02  \n",
       "1008111981822468102       0.0      0.0  1.0  1.0  1.0  9.999403e-01  \n",
       "2946543746                0.0      0.0  0.0  0.0  0.0  2.713931e-04  \n",
       "730545050388594690        0.0      0.0  1.0  0.0  0.0  4.399338e-01  \n",
       "1189756939                0.0      0.0  0.0  1.0  0.0  2.106733e-02  \n",
       "766167322109284352        0.0      0.0  0.0  1.0  0.0  6.770908e-02  \n",
       "24018964                  0.0      0.0  0.0  0.0  0.0  1.916163e-02  \n",
       "815281892345991180        0.0      0.0  0.0  0.0  0.0  4.151847e-03  \n",
       "388173846                 0.0      0.0  0.0  0.0  0.0  2.038922e-02  \n",
       "293290007                 1.0      0.0  0.0  1.0  0.0  1.234255e-01  \n",
       "2200576020                0.0      0.0  1.0  1.0  0.0  7.111508e-02  \n",
       "49324055                  0.0      0.0  0.0  1.0  0.0  1.037926e-02  \n",
       "560326682                 0.0      0.0  0.0  0.0  0.0  2.136971e-02  \n",
       "556955675                 0.0      0.0  0.0  1.0  0.0  7.407551e-02  \n",
       "310028318                 0.0      0.0  1.0  1.0  0.0  3.042047e-04  \n",
       "249739297                 0.0      0.0  0.0  0.0  0.0  1.203258e-01  \n",
       "...                       ...      ...  ...  ...  ...           ...  \n",
       "1589251639                0.0      0.0  0.0  0.0  0.0  3.420114e-01  \n",
       "1512416822                0.0      0.0  0.0  1.0  0.0  1.813938e-02  \n",
       "3167639097                0.0      0.0  0.0  0.0  0.0  5.876086e-08  \n",
       "887623959688171520        0.0      0.0  0.0  0.0  0.0  4.737588e-02  \n",
       "706133453339807744        0.0      0.0  0.0  0.0  0.0  1.410450e-05  \n",
       "956912991244570624        0.0      0.0  0.0  0.0  0.0  3.953828e-05  \n",
       "999687825497968640        0.0      0.0  0.0  0.0  0.0  8.205622e-03  \n",
       "848232140332519424        1.0      1.0  0.0  0.0  0.0  4.577145e-01  \n",
       "39564929                  0.0      0.0  0.0  0.0  0.0  1.325929e-02  \n",
       "881319251453333504        0.0      0.0  0.0  0.0  0.0  2.131989e-01  \n",
       "2231658049                0.0      0.0  1.0  1.0  0.0  9.232862e-02  \n",
       "1030089505460637696       0.0      0.0  0.0  1.0  1.0  6.998093e-01  \n",
       "18691648                  0.0      0.0  1.0  1.0  0.0  1.056782e-01  \n",
       "817825777932607489        0.0      0.0  1.0  1.0  0.0  9.872624e-03  \n",
       "21915395                  0.0      0.0  0.0  1.0  0.0  3.328680e-03  \n",
       "355739210                 0.0      0.0  0.0  1.0  0.0  4.191036e-02  \n",
       "150931027                 0.0      0.0  0.0  0.0  0.0  5.524966e-03  \n",
       "1011246062315687937       0.0      0.0  1.0  0.0  1.0  9.981698e-01  \n",
       "900437891373047809        0.0      0.0  0.0  1.0  0.0  6.604716e-02  \n",
       "32523862                  0.0      0.0  0.0  0.0  0.0  1.551734e-04  \n",
       "40040033                  0.0      0.0  1.0  0.0  0.0  3.698041e-02  \n",
       "89265769                  0.0      0.0  0.0  0.0  0.0  2.927092e-01  \n",
       "2770095723                0.0      0.0  0.0  1.0  0.0  9.508959e-02  \n",
       "21786220                  1.0      1.0  0.0  0.0  0.0  1.653877e-01  \n",
       "1044666765790334978       0.0      0.0  1.0  0.0  1.0  1.000000e+00  \n",
       "559955566                 0.0      0.0  0.0  0.0  0.0  2.705810e-04  \n",
       "870274473391398912        0.0      0.0  0.0  0.0  0.0  8.247090e-02  \n",
       "930214719062908928        0.0      0.0  0.0  0.0  0.0  3.829270e-03  \n",
       "594030193                 0.0      0.0  0.0  0.0  0.0  8.065634e-03  \n",
       "850161357295112194        0.0      0.0  0.0  0.0  0.0  2.807972e-02  \n",
       "\n",
       "[898 rows x 11 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bot_detection_df.to_csv('bot_detection_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CuD5S8xHr0v8",
    "bODKODK7r0wM",
    "BJ6o10MGr0wT"
   ],
   "name": "Twitter_API_group15.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
